{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4d063c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import sys\n",
    "\n",
    "from collections import defaultdict\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchmetrics\n",
    "\n",
    "import lightning as L\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c06e73e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc8374bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilities.data_downloader import train_val_test_downloader\n",
    "from utilities.upsampling import upsampling\n",
    "from utilities.plots import plt, COLORMAP, visualize_latent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c0b03a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from warnings import simplefilter\n",
    "simplefilter(\"ignore\", category=RuntimeWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e7fd637",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def set_random_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "set_random_seed(42)\n",
    "L.seed_everything(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa72713",
   "metadata": {},
   "source": [
    "# Description\n",
    "\n",
    "bla bla"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5b8852",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "bla bla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d0126d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets downloaded\n",
      " - train  : 810 entries\n",
      " - val    : 174 entries\n",
      " - test   : 174 entries\n",
      " - labels : 1158 entries\n"
     ]
    }
   ],
   "source": [
    "train, val, test, labels = train_val_test_downloader('interp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60ec389c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_upsampled = upsampling(train)\n",
    "len(train_upsampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "466277ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LightCurveDataset(Dataset):\n",
    "    def __init__(self, dataframe:pd.DataFrame,\n",
    "                 data_col:str='lgRate',\n",
    "                 weight_col:str='weight'):\n",
    "        \n",
    "        data = np.array(dataframe.loc[:, data_col].tolist(),\n",
    "                        dtype=np.float32)\n",
    "        weight = np.array(dataframe.loc[:, weight_col].tolist(),\n",
    "                          dtype=np.float32)\n",
    "        \n",
    "        self.data = torch.from_numpy(\n",
    "            data).unsqueeze(dim=1)   # value\n",
    "        self.weight = torch.from_numpy(\n",
    "            weight).unsqueeze(dim=1) # weight\n",
    "\n",
    "        # using dataframe index = event names \n",
    "        # as labels\n",
    "        labels = dataframe.index\n",
    "        self.label_enc = LabelEncoder()\n",
    "        self.labels = torch.as_tensor(self.label_enc.fit_transform(labels))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx], self.weight[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b1d85aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, val_dataset, test_dataset = (\n",
    "    LightCurveDataset(train_upsampled),\n",
    "    LightCurveDataset(val),\n",
    "    LightCurveDataset(test)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "05e5eeed",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset,\n",
    "                          batch_size=256,\n",
    "                          shuffle=True,\n",
    "                          num_workers=0)\n",
    "val_loader = DataLoader(val_dataset,\n",
    "                        batch_size=256,\n",
    "                        shuffle=False,\n",
    "                        num_workers=0)\n",
    "test_loader = DataLoader(test_dataset,\n",
    "                         batch_size=256,\n",
    "                         shuffle=False,\n",
    "                         num_workers=0)\n",
    "\n",
    "# for predictions on non-augmented train:\n",
    "train_loader_ = DataLoader(LightCurveDataset(train),\n",
    "                           batch_size=256,\n",
    "                           shuffle=False,\n",
    "                           num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae2b77d",
   "metadata": {},
   "source": [
    "# Model\n",
    "bla bla"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9489383f",
   "metadata": {},
   "source": [
    "## Torch Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "290613ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, latent_dim:int,\n",
    "                 architecture:tuple=(32, 4),\n",
    "                 tseries_length:int=64):\n",
    "        super().__init__()\n",
    "\n",
    "        self.hidden_dims = [\n",
    "            architecture[0]* 2**pow for pow in range(architecture[1])\n",
    "            ]                                       # num of filters in layers\n",
    "        self.tseries_length = tseries_length\n",
    "\n",
    "        modules = []\n",
    "        in_channels = 1                             # initial num of channels\n",
    "        for h_dim in self.hidden_dims:              # conv layers\n",
    "            modules.append(\n",
    "                nn.Sequential(\n",
    "                    nn.Conv1d(\n",
    "                        in_channels=in_channels,    # num of input channels\n",
    "                        out_channels=h_dim,         # num of output channels\n",
    "                        kernel_size=3,\n",
    "                        stride=2,                   # convolution kernel step\n",
    "                        padding=1,                  # save shape\n",
    "                    ),\n",
    "                    nn.BatchNorm1d(h_dim),\n",
    "                    nn.LeakyReLU(),\n",
    "                )\n",
    "            )\n",
    "            in_channels = h_dim                     # changing num of \n",
    "                                                    # input channels for \n",
    "                                                    # next iteration\n",
    "\n",
    "        modules.append(nn.Flatten())                # to vector\n",
    "        intermediate_dim = (\n",
    "            self.hidden_dims[-1] * \n",
    "            self.tseries_length // (2**len(self.hidden_dims))\n",
    "        )\n",
    "        modules.append(nn.Linear(in_features=intermediate_dim,\n",
    "                                 out_features=latent_dim))\n",
    "\n",
    "        self.encoder = nn.Sequential(*modules)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, latent_dim:int,\n",
    "                 architecture:tuple=(32, 4),\n",
    "                 tseries_length:int=64):\n",
    "        super().__init__()\n",
    "        self.hidden_dims = [\n",
    "            architecture[0]* 2**pow for pow in range(architecture[1]-1, 0, -1)\n",
    "            ]                                       # num of filters in layers\n",
    "        self.tseries_length = tseries_length\n",
    "\n",
    "        intermediate_dim = (\n",
    "            self.hidden_dims[0] * \n",
    "            self.tseries_length // (2**len(self.hidden_dims))\n",
    "        )\n",
    "        self.linear = nn.Linear(in_features=latent_dim,\n",
    "                                out_features=intermediate_dim)\n",
    "\n",
    "        modules = []\n",
    "        for i in range(len(self.hidden_dims) - 1):  # define upsample layers\n",
    "            modules.append(\n",
    "                nn.Sequential(\n",
    "                    nn.Upsample(scale_factor=2),\n",
    "                    nn.Conv1d(\n",
    "                        in_channels=self.hidden_dims[i],\n",
    "                        out_channels=self.hidden_dims[i + 1],\n",
    "                        kernel_size=3,\n",
    "                        padding=1,\n",
    "                    ),\n",
    "                    nn.BatchNorm1d(self.hidden_dims[i + 1]),\n",
    "                    nn.LeakyReLU(),\n",
    "                )\n",
    "            )\n",
    "\n",
    "        modules.append(\n",
    "            nn.Sequential(\n",
    "                nn.Upsample(scale_factor=2),\n",
    "                nn.Conv1d(in_channels=self.hidden_dims[-1],\n",
    "                          out_channels=1,\n",
    "                          kernel_size=3, padding=1)\n",
    "            )\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(*modules)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)        # from latents space to Linear\n",
    "        x = x.view(\n",
    "            -1, self.hidden_dims[0],\n",
    "            self.tseries_length // (2**len(self.hidden_dims))\n",
    "            )                     # reshape\n",
    "        x = self.decoder(x)       # reconstruction\n",
    "        return x\n",
    "\n",
    "class VAEncoder(Encoder):\n",
    "    def __init__(self, latent_dim):\n",
    "        if latent_dim % 2 != 0:   # check for the parity of the latent space\n",
    "            raise Exception('Latent size for VAEncoder must be even')\n",
    "\n",
    "        super().__init__(latent_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902b372b",
   "metadata": {},
   "source": [
    "## Lightning wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fce0b3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LitAE(L.LightningModule):\n",
    "    def __init__(self, encoder, decoder, derivative_weight=1.0):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.derivative_weight = derivative_weight\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=1e-4)\n",
    "\n",
    "    def forward_handler(self, data,\n",
    "                        *args, **kwargs):\n",
    "        # here is the logic how data is moved through AE\n",
    "        latent = self.encoder(data)\n",
    "        recon = self.decoder(latent)\n",
    "        return latent, recon\n",
    "\n",
    "    def loss_handler(self, recon, data, weight, latent,\n",
    "                     *args, **kwargs):\n",
    "        # here is the loss function computing\n",
    "        recon_loss = torch.masked_select(\n",
    "            input = F.mse_loss(\n",
    "                recon, data, reduction='none'\n",
    "            ) * weight,\n",
    "            mask = weight.ge(0.0)\n",
    "        )\n",
    "        recon_loss = recon_loss.mean()\n",
    "\n",
    "        # derivative penalty = \n",
    "        # L1-regularization of the output timeseries\n",
    "        derivative_loss = torch.abs(\n",
    "            torch.diff(recon, dim=-1)\n",
    "        ).mean()\n",
    "\n",
    "        # total loss\n",
    "        loss = recon_loss + self.derivative_weight * derivative_loss\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        data, labels, weight = batch\n",
    "\n",
    "        latent, recon = self.forward_handler(data, labels)\n",
    "        loss = self.loss_handler(recon, data, weight, latent)\n",
    "\n",
    "        self.log('train_loss', loss, on_step=False, on_epoch=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        data, labels, weight = batch\n",
    "\n",
    "        latent, recon = self.forward_handler(data, labels)\n",
    "        loss = self.loss_handler(recon, data, weight, latent)\n",
    "\n",
    "        self.log('val_loss', loss, on_step=False, on_epoch=True)\n",
    "        return loss\n",
    "\n",
    "    def on_test_epoch_start(self):\n",
    "        # create dict with empty tensors for further accumulating over batches\n",
    "        self.test_result = defaultdict(torch.Tensor)\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        data, labels, weight = batch\n",
    "\n",
    "        latent, recon = self.forward_handler(data, labels)\n",
    "        self.update_test_result(data, weight, recon, latent, labels)\n",
    "\n",
    "    def update_test_result(self, data, weight, recon, latent, labels):\n",
    "        # accumulating results every batch\n",
    "        self.test_result['real'] = torch.cat(\n",
    "            [self.test_result['real'], data.cpu()]\n",
    "        )\n",
    "        self.test_result['weight'] = torch.cat(\n",
    "            [self.test_result['weight'], weight.cpu()]\n",
    "        )\n",
    "        self.test_result['recon'] = torch.cat(\n",
    "            [self.test_result['recon'], recon.cpu()]\n",
    "        )\n",
    "        self.test_result['latent'] = torch.cat(\n",
    "            [self.test_result['latent'], latent.cpu()]\n",
    "        )\n",
    "        self.test_result['labels'] = torch.cat(\n",
    "            [self.test_result['labels'], labels.cpu()]\n",
    "        )\n",
    "\n",
    "    def on_test_epoch_end(self):\n",
    "        # simply change type from torch tensor to numpy array\n",
    "        # for every item in test_result dictionary\n",
    "        for key in self.test_result:\n",
    "            self.test_result[key] = self.test_result[key].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "95e26cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LitVAE(LitAE):\n",
    "    def __init__(self, encoder, decoder,\n",
    "                 derivative_weight=1.0,\n",
    "                 kld_weight=0.005,\n",
    "                 ):\n",
    "        super().__init__(encoder, decoder, derivative_weight)\n",
    "        self.kld_weight = kld_weight\n",
    "\n",
    "    def vae_split(self, latent):\n",
    "        size = (\n",
    "            latent.shape[1] // 2\n",
    "        )  # divide the latent representation into mu and log_var\n",
    "        mu = latent[:, :size]\n",
    "        log_var = latent[:, size:]\n",
    "        return mu, log_var\n",
    "\n",
    "    def vae_reparametrize(self, mu, log_var):\n",
    "        sigma = torch.exp(0.5 * log_var)\n",
    "        eps = torch.randn(mu.shape[0], mu.shape[1]).to(self.device)\n",
    "        return eps * sigma + mu\n",
    "\n",
    "    def kld_loss(self, mu, log_var):\n",
    "        var = log_var.exp()\n",
    "        kl_loss = torch.mean(\n",
    "            -0.5 * torch.sum(log_var - var - mu**2 + 1, dim=1), dim=0\n",
    "        )\n",
    "        return kl_loss\n",
    "\n",
    "    def forward_handler(self, data, *args, **kwargs):\n",
    "        # here is the logic how data is moved through AE\n",
    "        latent = self.encoder(data)\n",
    "\n",
    "        mu, log_var = self.vae_split(latent)\n",
    "        sample = self.vae_reparametrize(mu, log_var)\n",
    "\n",
    "        recon = self.decoder(sample)\n",
    "        return latent, recon\n",
    "\n",
    "    def loss_handler(self, recon, data, weight, latent, *args, **kwargs):\n",
    "        mu, log_var = self.vae_split(latent)\n",
    "        # here is the loss function computing\n",
    "        loss = torch.masked_select(\n",
    "            input = F.mse_loss(recon, data, reduction='none') * weight,\n",
    "            mask = weight.ge(0.0)).mean() + self.derivative_weight * torch.abs(\n",
    "            torch.diff(recon, dim=-1)\n",
    "            ).mean() + self.kld_weight * self.kld_loss(mu, log_var)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073c03ae",
   "metadata": {},
   "source": [
    "## Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "75b3d121",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reparametrize_latent(vae, latent):\n",
    "    mu, log_var = vae.vae_split(latent)\n",
    "    var = np.exp(log_var)\n",
    "\n",
    "    mu, log_var = torch.tensor(mu), torch.tensor(log_var)\n",
    "    sample = vae.vae_reparametrize(mu, log_var).numpy()\n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "16f649ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dict_result(trainer, model, dataloader, ckpt_path):\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        trainer.test(model, dataloader, ckpt_path=ckpt_path)\n",
    "    model.test_result[\n",
    "        'labels'\n",
    "    ]=dataloader.dataset.label_enc.inverse_transform(\n",
    "    model.test_result[\n",
    "        'labels'\n",
    "        ].astype(int)\n",
    "    )\n",
    "\n",
    "    real = model.test_result['real'].squeeze()\n",
    "    recon = model.test_result['recon'].squeeze()\n",
    "    weight = model.test_result['weight'].squeeze()\n",
    "\n",
    "\n",
    "    weightedMSE = (real-recon)**2 * weight\n",
    "    pred_errors = (weightedMSE ** 0.5).tolist()\n",
    "\n",
    "    weightedMSE = np.ma.masked_array(data=weightedMSE,\n",
    "                                     mask=~(weight.astype(bool))\n",
    "    )\n",
    "    weightedMSE = weightedMSE.mean(axis=1, keepdims=True)\n",
    "\n",
    "    latent = model.test_result['latent'].copy()\n",
    "\n",
    "    if hasattr(model, 'vae_reparametrize') and callable(model.vae_reparametrize):\n",
    "        # for VAE, we must reparametrize latent first\n",
    "        latent = reparametrize_latent(model, latent)\n",
    "\n",
    "    latentdim = latent.shape[-1]\n",
    "\n",
    "    latent = pd.DataFrame(\n",
    "        data=np.concatenate((latent, weightedMSE), axis=1),\n",
    "        index=model.test_result['labels'],\n",
    "        columns=['feature_'+str(dim) for dim in range(latentdim)]+['wMSE'])\n",
    "\n",
    "    latent.insert(loc=latent_dim+1, column='pred_error', value=pred_errors)\n",
    "\n",
    "    return latent, real, recon, weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fddbf111",
   "metadata": {},
   "source": [
    "# Training Models & Get Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f932e606-3a50-4182-a66a-26b99b89a1bb",
   "metadata": {},
   "source": [
    "## Standard Architecture (32, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f7b10a-6c6f-4c2e-9a05-09c646420b29",
   "metadata": {},
   "source": [
    "#### Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bc13d912",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 3\n",
    "\n",
    "encoder, decoder = Encoder(latent_dim), Decoder(latent_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "89f19554",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Encoder(\n",
       "  (encoder): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Conv1d(1, 32, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "      (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Conv1d(32, 64, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "      (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Conv1d(64, 128, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): Conv1d(128, 256, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (4): Flatten(start_dim=1, end_dim=-1)\n",
       "    (5): Linear(in_features=1024, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fccda5a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Decoder(\n",
       "  (linear): Linear(in_features=3, out_features=2048, bias=True)\n",
       "  (decoder): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Upsample(scale_factor=2.0, mode='nearest')\n",
       "      (1): Conv1d(256, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Upsample(scale_factor=2.0, mode='nearest')\n",
       "      (1): Conv1d(128, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Upsample(scale_factor=2.0, mode='nearest')\n",
       "      (1): Conv1d(64, 1, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "87102ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf lightning_logs\n",
    "!mkdir lightning_logs\n",
    "!mkdir lightning_logs/AE_latent_dim={latent_dim}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a51baa-9191-4ed0-bd11-c6ac1c406319",
   "metadata": {},
   "source": [
    "#### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7dc6f9da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-1c80317fa3b1799d\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-1c80317fa3b1799d\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6011;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir lightning_logs/AE_latent_dim={latent_dim} --port 6011"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e7715518",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "autoencoder = LitAE(encoder, decoder)\n",
    "\n",
    "exp_name = f'AE_latent_dim={latent_dim}'\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=f'./lightning_logs/AE_latent_dim={latent_dim}',\n",
    "    filename='best', monitor='val_loss', mode='min')\n",
    "\n",
    "early_stopping_callback = EarlyStopping(\n",
    "    monitor='val_loss', mode='min', min_delta=0, patience=20)\n",
    "\n",
    "logger = TensorBoardLogger(save_dir='./lightning_logs', name=exp_name)\n",
    "\n",
    "trainer = L.Trainer(max_epochs=500, logger=logger,\n",
    "                    callbacks=[checkpoint_callback, early_stopping_callback],\n",
    "                    enable_progress_bar=False\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff1d805",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainer.fit(autoencoder, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "27bddde1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model logged at ./AutoEncStdDim3\n"
     ]
    }
   ],
   "source": [
    "LOGDIR = f'lightning_logs/AE_latent_dim={latent_dim}'\n",
    "available_versions = sorted([\n",
    "    '/'+ver for ver in\n",
    "    os.listdir(LOGDIR)\n",
    "    if ver.startswith('version')\n",
    "])\n",
    "LOGDIR_LATEST = LOGDIR + available_versions[-1]\n",
    "\n",
    "DIR_SAVE = f'./AutoEncStdDim{latent_dim}'\n",
    "if not os.path.exists(DIR_SAVE):\n",
    "    os.mkdir(DIR_SAVE)\n",
    "\n",
    "shutil.copytree(LOGDIR_LATEST, DIR_SAVE, dirs_exist_ok=True)\n",
    "shutil.copyfile(LOGDIR+'/best.ckpt', DIR_SAVE+'/best.ckpt')\n",
    "print(f'model logged at {DIR_SAVE}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c35de50-e374-43a2-a542-2a9a14870170",
   "metadata": {},
   "source": [
    "#### Get Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d73d2d9-2a65-4103-b378-9979f89f8b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_upsampled_latent, real, recon, weight = get_dict_result(\n",
    "    trainer, autoencoder, train_loader, 'best')\n",
    "log10wMSE = np.log10(train_upsampled_latent['wMSE'].values)\n",
    "np.save(f'{DIR_SAVE}/log10wMSE.npy', log10wMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb925a1-b6ce-4245-b109-c93be047eee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_latent, real, recon, weight = get_dict_result(\n",
    "    trainer, autoencoder, train_loader_, 'best')\n",
    "val_latent, real, recon, weight = get_dict_result(\n",
    "    trainer, autoencoder, val_loader, 'best')\n",
    "test_latent, real, recon, weight = get_dict_result(\n",
    "    trainer, autoencoder, test_loader, 'best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b755e257-f655-4829-a73c-b78adf62315f",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_df = pd.concat(\n",
    "    (train_latent, val_latent, test_latent),\n",
    "    axis=0, ignore_index=False\n",
    ")\n",
    "latent_df['sample'] = (\n",
    "    ['train'] * len(train_latent) +\n",
    "    ['val'] * len(val_latent)+\n",
    "    ['test'] * len(test_latent)\n",
    ")\n",
    "latent_df.to_csv(f'{DIR_SAVE}/latent.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d408e4d2-1c4a-40f7-a37e-de83138e2ccd",
   "metadata": {},
   "source": [
    "## 'Purblind' Architecture (16, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b66ab462-01eb-4b4a-a489-d1e6f65bf849",
   "metadata": {},
   "source": [
    "#### Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d4fbb6c1-d056-433c-9765-a4225cfdb957",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 3\n",
    "architecture = (16, 4)\n",
    "\n",
    "encoder_purblind, decoder_purblind = (\n",
    "    Encoder(latent_dim, architecture=architecture),\n",
    "    Decoder(latent_dim, architecture=architecture)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3d028305-45f4-4522-8e0a-3170833b2b75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Encoder(\n",
       "  (encoder): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Conv1d(1, 16, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "      (1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Conv1d(16, 32, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "      (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Conv1d(32, 64, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "      (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): Conv1d(64, 128, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (4): Flatten(start_dim=1, end_dim=-1)\n",
       "    (5): Linear(in_features=512, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_purblind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c44e1865-c227-4019-b449-c465aed1210a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Decoder(\n",
       "  (linear): Linear(in_features=3, out_features=1024, bias=True)\n",
       "  (decoder): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Upsample(scale_factor=2.0, mode='nearest')\n",
       "      (1): Conv1d(128, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Upsample(scale_factor=2.0, mode='nearest')\n",
       "      (1): Conv1d(64, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Upsample(scale_factor=2.0, mode='nearest')\n",
       "      (1): Conv1d(32, 1, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_purblind"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed67c9d0-31f9-475c-899e-35b10c99786d",
   "metadata": {},
   "source": [
    "#### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f888d9-9bb6-4d77-b2f8-2f2b25b9ff42",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir lightning_logs/purblindAE_latent_dim={latent_dim}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b8922c8f-372b-4db4-8d1e-af4602c920eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-bdd640fb06671ad1\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-bdd640fb06671ad1\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6013;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir lightning_logs/purblindAE_latent_dim={latent_dim} --port 6013"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0f583de7-1b46-41e0-8a94-beb9c3747edf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "purblind_autoencoder = LitAE(encoder_purblind, decoder_purblind)\n",
    "\n",
    "exp_name = f'purblindAE_latent_dim={latent_dim}'\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=f'./lightning_logs/purblindAE_latent_dim={latent_dim}',\n",
    "    filename='best', monitor='val_loss', mode='min')\n",
    "\n",
    "early_stopping_callback = EarlyStopping(\n",
    "    monitor='val_loss', mode='min', min_delta=0, patience=20)\n",
    "\n",
    "logger = TensorBoardLogger(save_dir='./lightning_logs', name=exp_name)\n",
    "\n",
    "trainer = L.Trainer(max_epochs=500, logger=logger,\n",
    "                    callbacks=[checkpoint_callback, early_stopping_callback],\n",
    "                    enable_progress_bar=False\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c987cf2-69fc-41ef-ab2b-22b077d9a0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(purblind_autoencoder, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "11079cb5-b392-4f28-a587-88424c4e78ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model logged at ./AutoEncPurblindDim3\n"
     ]
    }
   ],
   "source": [
    "LOGDIR = f'lightning_logs/purblindAE_latent_dim={latent_dim}'\n",
    "available_versions = sorted([\n",
    "    '/'+ver for ver in\n",
    "    os.listdir(LOGDIR)\n",
    "    if ver.startswith('version')\n",
    "])\n",
    "LOGDIR_LATEST = LOGDIR + available_versions[-1]\n",
    "\n",
    "DIR_SAVE = f'./AutoEncPurblindDim{latent_dim}'\n",
    "if not os.path.exists(DIR_SAVE):\n",
    "    os.mkdir(DIR_SAVE)\n",
    "\n",
    "shutil.copytree(LOGDIR_LATEST, DIR_SAVE, dirs_exist_ok=True)\n",
    "shutil.copyfile(LOGDIR+'/best.ckpt', DIR_SAVE+'/best.ckpt')\n",
    "print(f'model logged at {DIR_SAVE}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec37e98f-299e-4424-ba09-271e77953558",
   "metadata": {},
   "source": [
    "#### Get Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e564fea8-3cda-404c-aece-26a793b1dcbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_upsampled_latent, real, recon, weight = get_dict_result(\n",
    "    trainer, purblind_autoencoder, train_loader, 'best')\n",
    "log10wMSE = np.log10(train_upsampled_latent['wMSE'].values)\n",
    "np.save(f'{DIR_SAVE}/log10wMSE.npy', log10wMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4569a53-9484-4034-9834-352cc8366f0b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_latent, real, recon, weight = get_dict_result(\n",
    "    trainer, purblind_autoencoder, train_loader_, 'best')\n",
    "val_latent, real, recon, weight = get_dict_result(\n",
    "    trainer, purblind_autoencoder, val_loader, 'best')\n",
    "test_latent, real, recon, weight = get_dict_result(\n",
    "    trainer, purblind_autoencoder, test_loader, 'best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "663eb19d-6ee2-4d72-899d-7ba066b88b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_df = pd.concat(\n",
    "    (train_latent, val_latent, test_latent),\n",
    "    axis=0, ignore_index=False\n",
    ")\n",
    "latent_df['sample'] = (\n",
    "    ['train'] * len(train_latent) +\n",
    "    ['val'] * len(val_latent)+\n",
    "    ['test'] * len(test_latent)\n",
    ")\n",
    "latent_df.to_csv(f'{DIR_SAVE}/latent.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18985c6d-8312-4d97-9f1e-bcb54615d8ed",
   "metadata": {},
   "source": [
    "## 'Tiny' Architecture (32, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e78eb1-bd0d-46fe-af51-752fc3fe6a3e",
   "metadata": {},
   "source": [
    "#### Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d29afc0f-70ed-4843-a7c4-f10a14ec92ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 3\n",
    "architecture = (32, 2)\n",
    "\n",
    "encoder_tiny, decoder_tiny = (\n",
    "    Encoder(latent_dim, architecture=architecture),\n",
    "    Decoder(latent_dim, architecture=architecture)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ccc34e89-03b1-4511-bfe9-4eec9a95341c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Encoder(\n",
       "  (encoder): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Conv1d(1, 32, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "      (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Conv1d(32, 64, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "      (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (2): Flatten(start_dim=1, end_dim=-1)\n",
       "    (3): Linear(in_features=1024, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_tiny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0592b982-2ff8-468e-a7e1-017e1d1f2728",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Decoder(\n",
       "  (linear): Linear(in_features=3, out_features=2048, bias=True)\n",
       "  (decoder): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Upsample(scale_factor=2.0, mode='nearest')\n",
       "      (1): Conv1d(64, 1, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_tiny"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a3f1fd-4cb7-4df5-97c7-627807db4309",
   "metadata": {},
   "source": [
    "#### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "70820cab-9a79-4577-a6a7-0b404de9f885",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir lightning_logs/tinyAE_latent_dim={latent_dim}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "66a14030-6711-4202-951c-b29be9d8f5eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-3eb13b9046685257\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-3eb13b9046685257\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6015;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir lightning_logs/tinyAE_latent_dim={latent_dim} --port 6015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7e437265-64c8-4f05-9cd8-0bc36b351852",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "tiny_autoencoder = LitAE(encoder_tiny, decoder_tiny)\n",
    "\n",
    "exp_name = f'tinyAE_latent_dim={latent_dim}'\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=f'./lightning_logs/tinyAE_latent_dim={latent_dim}',\n",
    "    filename='best', monitor='val_loss', mode='min')\n",
    "\n",
    "early_stopping_callback = EarlyStopping(\n",
    "    monitor='val_loss', mode='min', min_delta=0, patience=20)\n",
    "\n",
    "logger = TensorBoardLogger(save_dir='./lightning_logs', name=exp_name)\n",
    "\n",
    "trainer = L.Trainer(max_epochs=500, logger=logger,\n",
    "                    callbacks=[checkpoint_callback, early_stopping_callback],\n",
    "                    enable_progress_bar=False\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6274b2ad-5191-4642-89dd-14f09742da97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nickolaymartynenko/miniconda3/envs/GRB_env/lib/python3.11/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /Users/nickolaymartynenko/Downloads/GRB-X-Ray-Afterglow/models/AutoEncoder/lightning_logs/tinyAE_latent_dim=3 exists and is not empty.\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | encoder | Encoder | 9.6 K  | train\n",
      "1 | decoder | Decoder | 8.4 K  | train\n",
      "--------------------------------------------\n",
      "18.0 K    Trainable params\n",
      "0         Non-trainable params\n",
      "18.0 K    Total params\n",
      "0.072     Total estimated model params size (MB)\n",
      "18        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/Users/nickolaymartynenko/miniconda3/envs/GRB_env/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "/Users/nickolaymartynenko/miniconda3/envs/GRB_env/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(tiny_autoencoder, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91add9e2-0519-482d-bcd2-882e4550e436",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOGDIR = f'lightning_logs/tinyAE_latent_dim={latent_dim}'\n",
    "available_versions = sorted([\n",
    "    '/'+ver for ver in\n",
    "    os.listdir(LOGDIR)\n",
    "    if ver.startswith('version')\n",
    "])\n",
    "LOGDIR_LATEST = LOGDIR + available_versions[-1]\n",
    "\n",
    "DIR_SAVE = f'./AutoEncTinyDim{latent_dim}'\n",
    "if not os.path.exists(DIR_SAVE):\n",
    "    os.mkdir(DIR_SAVE)\n",
    "\n",
    "shutil.copytree(LOGDIR_LATEST, DIR_SAVE, dirs_exist_ok=True)\n",
    "shutil.copyfile(LOGDIR+'/best.ckpt', DIR_SAVE+'/best.ckpt')\n",
    "print(f'model logged at {DIR_SAVE}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2d7602-d0c6-440a-9518-803d35b8ab78",
   "metadata": {},
   "source": [
    "#### Get Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2630434b-6858-4950-aec0-4e00fccc8a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_upsampled_latent, real, recon, weight = get_dict_result(\n",
    "    trainer, tiny_autoencoder, train_loader, 'best')\n",
    "log10wMSE = np.log10(train_upsampled_latent['wMSE'].values)\n",
    "np.save(f'{DIR_SAVE}/log10wMSE.npy', log10wMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059c887a-e4b0-413a-a3dd-50c0bae38594",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_latent, real, recon, weight = get_dict_result(\n",
    "    trainer, tiny_autoencoder, train_loader_, 'best')\n",
    "val_latent, real, recon, weight = get_dict_result(\n",
    "    trainer, tiny_autoencoder, val_loader, 'best')\n",
    "test_latent, real, recon, weight = get_dict_result(\n",
    "    trainer, tiny_autoencoder, test_loader, 'best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e447a08f-f30d-460b-8c57-ebd50e9a7331",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_df = pd.concat(\n",
    "    (train_latent, val_latent, test_latent),\n",
    "    axis=0, ignore_index=False\n",
    ")\n",
    "latent_df['sample'] = (\n",
    "    ['train'] * len(train_latent) +\n",
    "    ['val'] * len(val_latent)+\n",
    "    ['test'] * len(test_latent)\n",
    ")\n",
    "latent_df.to_csv(f'{DIR_SAVE}/latent.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14832d1-2c3c-4d43-8222-56af393ea6f6",
   "metadata": {},
   "source": [
    "## 'Compact' Architecture (16, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c19f08-bd0d-47b3-b3f5-279d3d45d8a7",
   "metadata": {},
   "source": [
    "#### Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce0480b-5adf-45f1-be6e-376590a12d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 3\n",
    "architecture = (16, 2)\n",
    "\n",
    "encoder_compact, decoder_compact = (\n",
    "    Encoder(latent_dim, architecture=architecture),\n",
    "    Decoder(latent_dim, architecture=architecture)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47af46f7-ec3c-40e7-8014-aa79c074a3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_compact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1cf54b-86e1-4392-ac61-a0f76a9d34dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_compact"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7768ac-ac05-4306-9fd9-3fc476c88b94",
   "metadata": {},
   "source": [
    "#### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e519fe07-059f-4fe3-a7bf-a2bb945d824c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir lightning_logs/compactAE_latent_dim={latent_dim}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9628a4-0054-430b-98b4-1ce84872582d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir lightning_logs/compactAE_latent_dim={latent_dim} --port 6017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9dc9b9a-685d-41e7-a4f9-3b0a03c487bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "compact_autoencoder = LitAE(encoder_compact, decoder_compact)\n",
    "\n",
    "exp_name = f'compactAE_latent_dim={latent_dim}'\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=f'./lightning_logs/compactAE_latent_dim={latent_dim}',\n",
    "    filename='best', monitor='val_loss', mode='min')\n",
    "\n",
    "early_stopping_callback = EarlyStopping(\n",
    "    monitor='val_loss', mode='min', min_delta=0, patience=20)\n",
    "\n",
    "logger = TensorBoardLogger(save_dir='./lightning_logs', name=exp_name)\n",
    "\n",
    "trainer = L.Trainer(max_epochs=500, logger=logger,\n",
    "                    callbacks=[checkpoint_callback, early_stopping_callback],\n",
    "                    enable_progress_bar=False\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d15a81-5d62-4b89-a0fe-dcc6de139a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(compact_autoencoder, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f1b51d-4107-43e1-9e13-c18181bdab91",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOGDIR = f'lightning_logs/compactAE_latent_dim={latent_dim}'\n",
    "available_versions = sorted([\n",
    "    '/'+ver for ver in\n",
    "    os.listdir(LOGDIR)\n",
    "    if ver.startswith('version')\n",
    "])\n",
    "LOGDIR_LATEST = LOGDIR + available_versions[-1]\n",
    "\n",
    "DIR_SAVE = f'./AutoEncCompactDim{latent_dim}'\n",
    "if not os.path.exists(DIR_SAVE):\n",
    "    os.mkdir(DIR_SAVE)\n",
    "\n",
    "shutil.copytree(LOGDIR_LATEST, DIR_SAVE, dirs_exist_ok=True)\n",
    "shutil.copyfile(LOGDIR+'/best.ckpt', DIR_SAVE+'/best.ckpt')\n",
    "print(f'model logged at {DIR_SAVE}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e90a49-e920-45d8-a94e-062a81b42d50",
   "metadata": {},
   "source": [
    "#### Get Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49268116-f30f-46c7-a963-08b164e66bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_upsampled_latent, real, recon, weight = get_dict_result(\n",
    "    trainer, compact_autoencoder, train_loader, 'best')\n",
    "log10wMSE = np.log10(train_upsampled_latent['wMSE'].values)\n",
    "np.save(f'{DIR_SAVE}/log10wMSE.npy', log10wMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216739b9-5f70-4957-a3b2-a3a9523d873c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_latent, real, recon, weight = get_dict_result(\n",
    "    trainer, compact_autoencoder, train_loader_, 'best')\n",
    "val_latent, real, recon, weight = get_dict_result(\n",
    "    trainer, compact_autoencoder, val_loader, 'best')\n",
    "test_latent, real, recon, weight = get_dict_result(\n",
    "    trainer, compact_autoencoder, test_loader, 'best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d397fdc4-9be4-4a37-a4d2-15eb337d3739",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_df = pd.concat(\n",
    "    (train_latent, val_latent, test_latent),\n",
    "    axis=0, ignore_index=False\n",
    ")\n",
    "latent_df['sample'] = (\n",
    "    ['train'] * len(train_latent) +\n",
    "    ['val'] * len(val_latent)+\n",
    "    ['test'] * len(test_latent)\n",
    ")\n",
    "latent_df.to_csv(f'{DIR_SAVE}/latent.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595cb9b4-cf63-4958-aa85-de547226e555",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
