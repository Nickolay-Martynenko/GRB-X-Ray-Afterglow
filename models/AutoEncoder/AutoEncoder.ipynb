{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce4d063c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import joblib\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import sys\n",
    "\n",
    "from collections import defaultdict\n",
    "from scipy.special import log_ndtr, logsumexp\n",
    "from scipy.interpolate import Akima1DInterpolator\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchmetrics\n",
    "\n",
    "from tensorboard.backend.event_processing import event_accumulator\n",
    "\n",
    "import lightning as L\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c06e73e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc8374bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilities.data_downloader import train_val_test_downloader\n",
    "from utilities.upsampling import upsampling\n",
    "from utilities.extracted_features_explorer import explorer\n",
    "from utilities.plots import plt, COLORMAP, visualize_latent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c0b03a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from warnings import simplefilter, filterwarnings\n",
    "simplefilter(\"ignore\", category=RuntimeWarning)\n",
    "filterwarnings(\"ignore\", \".*does not have many workers.*\")\n",
    "filterwarnings(\"ignore\", \".*exists and is not empty.*\")\n",
    "filterwarnings(\"ignore\", \".*sampler has shuffling enabled.*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e7fd637",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def set_random_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "set_random_seed(42)\n",
    "L.seed_everything(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa72713",
   "metadata": {},
   "source": [
    "# Description\n",
    "\n",
    "Here we present **AutoEncoder** Model based on 1D Convolutional layers. A number of possible architectures are trained and logged. The experiments with various architectures are hard-coded.\n",
    "\n",
    "## Fitting\n",
    "The loss function is:\n",
    "\n",
    "$${\\rm Loss} = \\Bigg\\langle \\left[\\frac{\\log_{10}({\\rm rate}/{\\rm s}^{-1})_{\\rm reco} - \\log_{10}({\\rm rate}/{\\rm s}^{-1})_{\\rm true}}{\\log_{10}({\\rm rate}/{\\rm s}^{-1})~{\\rm err.}}\\right]^2\\Bigg\\rangle_{\\rm non-empty~bins}\\quad +\\quad\\delta \\cdot\\Bigg\\langle\\Big|{ \\Delta}_t \\log_{10}({\\rm rate}/{\\rm s}^{-1})_{\\rm reco}\\Big|\\Bigg\\rangle_{\\rm all~bins}$$\n",
    "\n",
    "The first term corresponds to weighted MSE, and the second one applies L1-regularization to a predicted timeseries. \n",
    "\n",
    "## Scoring procedure\n",
    "We infer the anomalous score from the weighted reconstruction error distribution.\n",
    "\n",
    "We fit the cumulative distribution function of the weighted reconstruction error decimal logarithm $\\lg[{\\rm wre}]$ using our custom Kernel Density Estimation procedure (which should be rather called Kernel Cumulative Distribution Estimation):\n",
    "\n",
    "$${\\rm CDF}(\\lg[{\\rm wre}]) = \\Bigg\\langle \\int\\limits_{-\\infty}^{\\lg[{\\rm wre}]} \\frac{d\\xi}{b\\sqrt{2\\pi}} \\exp\\Big[-\\frac{(\\xi - \\lg[{\\rm wre}_i])^2}{2b^2}\\Big]\\Bigg\\rangle_i = \\Bigg\\langle \\int\\limits_{-\\infty}^{\\frac{\\lg[{\\rm wre}] - \\lg[{\\rm wre}_i]}{b}} \\frac{d\\zeta}{\\sqrt{2\\pi}} \\exp\\Big[-\\frac{1}{2}\\zeta^2\\Big]\\Bigg\\rangle_i$$\n",
    "\n",
    "Bandwidth $b$ is defined by Silverman's rule of thumb, see [[reference]](https://archive.org/details/densityestimatio00silv_0/page/44/mode/2up).\n",
    "\n",
    "We then define $p$-value as $1-{\\rm CDF}$ and score samples accordingly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5b8852",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "We use linearly interpolated rebinned dataset. In order to enlarge testing set, we upsample it applying gaussian noise and random shift augmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d0126d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets downloaded\n",
      " - train  : 810 entries\n",
      " - val    : 174 entries\n",
      " - test   : 174 entries\n",
      " - labels : 1158 entries\n"
     ]
    }
   ],
   "source": [
    "train, val, test, labels = train_val_test_downloader('interp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60ec389c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upsampled training fragment length: 81000\n"
     ]
    }
   ],
   "source": [
    "train_upsampled = upsampling(train)\n",
    "print(f'Upsampled training fragment length: {len(train_upsampled)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "466277ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LightCurveDataset(Dataset):\n",
    "    def __init__(self, dataframe:pd.DataFrame,\n",
    "                 data_col:str='lgRate',\n",
    "                 weight_col:str='weight'):\n",
    "        \n",
    "        data = np.array(dataframe.loc[:, data_col].tolist(),\n",
    "                        dtype=np.float32)\n",
    "        weight = np.array(dataframe.loc[:, weight_col].tolist(),\n",
    "                          dtype=np.float32)\n",
    "        \n",
    "        self.data = torch.from_numpy(\n",
    "            data).unsqueeze(dim=1)   # value\n",
    "        self.weight = torch.from_numpy(\n",
    "            weight).unsqueeze(dim=1) # weight\n",
    "\n",
    "        # using dataframe index = event names \n",
    "        # as labels\n",
    "        labels = dataframe.index\n",
    "        self.label_enc = LabelEncoder()\n",
    "        self.labels = torch.as_tensor(self.label_enc.fit_transform(labels))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx], self.weight[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b1d85aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, val_dataset, test_dataset = (\n",
    "    LightCurveDataset(train_upsampled),\n",
    "    LightCurveDataset(val),\n",
    "    LightCurveDataset(test)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "05e5eeed",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset,\n",
    "                          batch_size=256,\n",
    "                          shuffle=True,\n",
    "                          num_workers=0)\n",
    "val_loader = DataLoader(val_dataset,\n",
    "                        batch_size=256,\n",
    "                        shuffle=False,\n",
    "                        num_workers=0)\n",
    "test_loader = DataLoader(test_dataset,\n",
    "                         batch_size=256,\n",
    "                         shuffle=False,\n",
    "                         num_workers=0)\n",
    "\n",
    "# for predictions on non-augmented train:\n",
    "train_loader_ = DataLoader(LightCurveDataset(train),\n",
    "                           batch_size=256,\n",
    "                           shuffle=False,\n",
    "                           num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae2b77d",
   "metadata": {},
   "source": [
    "# Model\n",
    "**AutoEncoder** Model based on the following block structure: 1D Convolutional layer + BatchNormalization + LeakyReLU activation.\n",
    "The number of channels growth trend is 2^(depth of the layer), the starting number of channels and the depth are architetural parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9489383f",
   "metadata": {},
   "source": [
    "## Torch Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "290613ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, latent_dim:int,\n",
    "                 architecture:tuple=(32, 4),\n",
    "                 tseries_length:int=64):\n",
    "        super().__init__()\n",
    "\n",
    "        self.hidden_dims = [\n",
    "            architecture[0]* 2**pow for pow in range(architecture[1])\n",
    "            ]                                       # num of filters in layers\n",
    "        self.tseries_length = tseries_length\n",
    "\n",
    "        modules = []\n",
    "        in_channels = 1                             # initial num of channels\n",
    "        for h_dim in self.hidden_dims:              # conv layers\n",
    "            modules.append(\n",
    "                nn.Sequential(\n",
    "                    nn.Conv1d(\n",
    "                        in_channels=in_channels,    # num of input channels\n",
    "                        out_channels=h_dim,         # num of output channels\n",
    "                        kernel_size=3,\n",
    "                        stride=2,                   # convolution kernel step\n",
    "                        padding=1,                  # save shape\n",
    "                    ),\n",
    "                    nn.BatchNorm1d(h_dim),\n",
    "                    nn.LeakyReLU(),\n",
    "                )\n",
    "            )\n",
    "            in_channels = h_dim                     # changing num of \n",
    "                                                    # input channels for \n",
    "                                                    # next iteration\n",
    "\n",
    "        modules.append(nn.Flatten())                # to vector\n",
    "        intermediate_dim = (\n",
    "            self.hidden_dims[-1] * \n",
    "            self.tseries_length // (2**len(self.hidden_dims))\n",
    "        )\n",
    "        modules.append(nn.Linear(in_features=intermediate_dim,\n",
    "                                 out_features=latent_dim))\n",
    "\n",
    "        self.encoder = nn.Sequential(*modules)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, latent_dim:int,\n",
    "                 architecture:tuple=(32, 4),\n",
    "                 tseries_length:int=64):\n",
    "        super().__init__()\n",
    "        self.hidden_dims = [\n",
    "            architecture[0]* 2**pow for pow in range(architecture[1]-1, 0, -1)\n",
    "            ]                                       # num of filters in layers\n",
    "        self.tseries_length = tseries_length\n",
    "\n",
    "        intermediate_dim = (\n",
    "            self.hidden_dims[0] * \n",
    "            self.tseries_length // (2**len(self.hidden_dims))\n",
    "        )\n",
    "        self.linear = nn.Linear(in_features=latent_dim,\n",
    "                                out_features=intermediate_dim)\n",
    "\n",
    "        modules = []\n",
    "        for i in range(len(self.hidden_dims) - 1):  # define upsample layers\n",
    "            modules.append(\n",
    "                nn.Sequential(\n",
    "                    nn.Upsample(scale_factor=2),\n",
    "                    nn.Conv1d(\n",
    "                        in_channels=self.hidden_dims[i],\n",
    "                        out_channels=self.hidden_dims[i + 1],\n",
    "                        kernel_size=3,\n",
    "                        padding=1,\n",
    "                    ),\n",
    "                    nn.BatchNorm1d(self.hidden_dims[i + 1]),\n",
    "                    nn.LeakyReLU(),\n",
    "                )\n",
    "            )\n",
    "\n",
    "        modules.append(\n",
    "            nn.Sequential(\n",
    "                nn.Upsample(scale_factor=2),\n",
    "                nn.Conv1d(in_channels=self.hidden_dims[-1],\n",
    "                          out_channels=1,\n",
    "                          kernel_size=3, padding=1)\n",
    "            )\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(*modules)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)        # from latents space to Linear\n",
    "        x = x.view(\n",
    "            -1, self.hidden_dims[0],\n",
    "            self.tseries_length // (2**len(self.hidden_dims))\n",
    "            )                     # reshape\n",
    "        x = self.decoder(x)       # reconstruction\n",
    "        return x\n",
    "\n",
    "# For Variational AE, not used here\n",
    "# =================================\n",
    "class VAEncoder(Encoder):\n",
    "    def __init__(self, latent_dim):\n",
    "        if latent_dim % 2 != 0:   # check for the parity of the latent space\n",
    "            raise Exception('Latent size for VAEncoder must be even')\n",
    "\n",
    "        super().__init__(latent_dim)\n",
    "# ================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902b372b",
   "metadata": {},
   "source": [
    "## Lightning wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fce0b3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LitAE(L.LightningModule):\n",
    "    def __init__(self, encoder, decoder, derivative_weight=1.0):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.derivative_weight = derivative_weight\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=1e-4)\n",
    "\n",
    "    def forward_handler(self, data,\n",
    "                        *args, **kwargs):\n",
    "        # here is the logic how data is moved through AE\n",
    "        latent = self.encoder(data)\n",
    "        recon = self.decoder(latent)\n",
    "        return latent, recon\n",
    "\n",
    "    def loss_handler(self, recon, data, weight, latent,\n",
    "                     *args, **kwargs):\n",
    "        # here is the loss function computing\n",
    "        recon_loss = torch.masked_select(\n",
    "            input = F.mse_loss(\n",
    "                recon, data, reduction='none'\n",
    "            ) * weight,\n",
    "            mask = weight.ge(0.0)\n",
    "        )\n",
    "        recon_loss = recon_loss.mean()\n",
    "\n",
    "        # derivative penalty = \n",
    "        # L1-regularization of the output timeseries\n",
    "        derivative_loss = torch.abs(\n",
    "            torch.diff(recon, dim=-1)\n",
    "        ).mean()\n",
    "\n",
    "        # total loss\n",
    "        loss = recon_loss + self.derivative_weight * derivative_loss\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        data, labels, weight = batch\n",
    "\n",
    "        latent, recon = self.forward_handler(data, labels)\n",
    "        loss = self.loss_handler(recon, data, weight, latent)\n",
    "\n",
    "        self.log('train_loss', loss, on_step=False, on_epoch=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        data, labels, weight = batch\n",
    "\n",
    "        latent, recon = self.forward_handler(data, labels)\n",
    "        loss = self.loss_handler(recon, data, weight, latent)\n",
    "\n",
    "        self.log('val_loss', loss, on_step=False, on_epoch=True)\n",
    "        return loss\n",
    "\n",
    "    def on_test_epoch_start(self):\n",
    "        # create dict with empty tensors for further accumulating over batches\n",
    "        self.test_result = defaultdict(torch.Tensor)\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        data, labels, weight = batch\n",
    "\n",
    "        latent, recon = self.forward_handler(data, labels)\n",
    "        self.update_test_result(data, weight, recon, latent, labels)\n",
    "\n",
    "    def update_test_result(self, data, weight, recon, latent, labels):\n",
    "        # accumulating results every batch\n",
    "        self.test_result['real'] = torch.cat(\n",
    "            [self.test_result['real'], data.cpu()]\n",
    "        )\n",
    "        self.test_result['weight'] = torch.cat(\n",
    "            [self.test_result['weight'], weight.cpu()]\n",
    "        )\n",
    "        self.test_result['recon'] = torch.cat(\n",
    "            [self.test_result['recon'], recon.cpu()]\n",
    "        )\n",
    "        self.test_result['latent'] = torch.cat(\n",
    "            [self.test_result['latent'], latent.cpu()]\n",
    "        )\n",
    "        self.test_result['labels'] = torch.cat(\n",
    "            [self.test_result['labels'], labels.cpu()]\n",
    "        )\n",
    "\n",
    "    def on_test_epoch_end(self):\n",
    "        # simply change type from torch tensor to numpy array\n",
    "        # for every item in test_result dictionary\n",
    "        for key in self.test_result:\n",
    "            self.test_result[key] = self.test_result[key].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "95e26cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Variational AE, not used here\n",
    "# =================================\n",
    "class LitVAE(LitAE):\n",
    "    def __init__(self, encoder, decoder,\n",
    "                 derivative_weight=1.0,\n",
    "                 kld_weight=0.005,\n",
    "                 ):\n",
    "        super().__init__(encoder, decoder, derivative_weight)\n",
    "        self.kld_weight = kld_weight\n",
    "\n",
    "    def vae_split(self, latent):\n",
    "        size = (\n",
    "            latent.shape[1] // 2\n",
    "        )  # divide the latent representation into mu and log_var\n",
    "        mu = latent[:, :size]\n",
    "        log_var = latent[:, size:]\n",
    "        return mu, log_var\n",
    "\n",
    "    def vae_reparametrize(self, mu, log_var):\n",
    "        sigma = torch.exp(0.5 * log_var)\n",
    "        eps = torch.randn(mu.shape[0], mu.shape[1]).to(self.device)\n",
    "        return eps * sigma + mu\n",
    "\n",
    "    def kld_loss(self, mu, log_var):\n",
    "        var = log_var.exp()\n",
    "        kl_loss = torch.mean(\n",
    "            -0.5 * torch.sum(log_var - var - mu**2 + 1, dim=1), dim=0\n",
    "        )\n",
    "        return kl_loss\n",
    "\n",
    "    def forward_handler(self, data, *args, **kwargs):\n",
    "        # here is the logic how data is moved through AE\n",
    "        latent = self.encoder(data)\n",
    "\n",
    "        mu, log_var = self.vae_split(latent)\n",
    "        sample = self.vae_reparametrize(mu, log_var)\n",
    "\n",
    "        recon = self.decoder(sample)\n",
    "        return latent, recon\n",
    "\n",
    "    def loss_handler(self, recon, data, weight, latent, *args, **kwargs):\n",
    "        mu, log_var = self.vae_split(latent)\n",
    "        # here is the loss function computing\n",
    "        loss = torch.masked_select(\n",
    "            input = F.mse_loss(recon, data, reduction='none') * weight,\n",
    "            mask = weight.ge(0.0)).mean() + self.derivative_weight * torch.abs(\n",
    "            torch.diff(recon, dim=-1)\n",
    "            ).mean() + self.kld_weight * self.kld_loss(mu, log_var)\n",
    "        return loss\n",
    "# ================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073c03ae",
   "metadata": {},
   "source": [
    "# Utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6518dcbd",
   "metadata": {},
   "source": [
    "#### Training loop utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4665556f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_models(latent_dim:int=3, architecture:tuple=(32, 4)):\n",
    "    \"\"\"\n",
    "    Creates autoencoder model instance\n",
    "    \"\"\"\n",
    "    encoder, decoder = (\n",
    "        Encoder(latent_dim=latent_dim, architecture=architecture),\n",
    "        Decoder(latent_dim=latent_dim, architecture=architecture)\n",
    "    )\n",
    "    autoencoder = LitAE(encoder, decoder)\n",
    "    exp_name = f'AE_dim={latent_dim}_archi=' + '%d_%d' % architecture\n",
    "    \n",
    "    os.mkdir('./lightning_logs/'+exp_name)\n",
    "    return encoder, decoder, autoencoder, exp_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "67c1a9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_latest_model(exp_name:str, target_dir:str):\n",
    "    \"\"\"\n",
    "    Saves the latest verison of the trained model\n",
    "    together with data collected during training loop\n",
    "    \n",
    "    Please note that target_dir, if exists,\n",
    "    will be completely overwritten!\n",
    "    \"\"\"\n",
    "    logdir = f'./lightning_logs/{exp_name}'\n",
    "    available_versions = sorted([\n",
    "        '/'+ver for ver in\n",
    "        os.listdir(logdir)\n",
    "        if ver.startswith('version')\n",
    "    ])\n",
    "    latest = logdir + available_versions[-1]\n",
    "    \n",
    "    if os.path.exists(target_dir):\n",
    "        shutil.rmtree(target_dir)\n",
    "    os.mkdir(target_dir)\n",
    "        \n",
    "    shutil.copytree(latest, target_dir, dirs_exist_ok=True)\n",
    "    shutil.copyfile(logdir+'/best.ckpt', target_dir+'/best.ckpt')\n",
    "    print(f'model logged at {target_dir}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e7f3d4",
   "metadata": {},
   "source": [
    "#### Learning curve visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c4917f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(event_acc_instance:event_accumulator.EventAccumulator, tag:str='train_loss'):\n",
    "    \"\"\"\n",
    "    Extracts info from EventAccumulator instance\n",
    "    \"\"\"\n",
    "    steps = []\n",
    "    values = []\n",
    "    for event in event_acc_instance.Scalars(tag):\n",
    "        steps.append(event.step)\n",
    "        values.append(event.value)\n",
    "    return steps, values\n",
    "\n",
    "def plot_learning_curve(target_dir:str, show:bool=True,\n",
    "                        cut:int=2, freq:int=10):\n",
    "    \"\"\"\n",
    "    Plots learning curve for train- and val- loss\n",
    "    \"\"\"\n",
    "    \n",
    "    event_files = [file for file in os.listdir(target_dir) if 'events.out.tfevents' in file]\n",
    "    num_files = len(event_files)\n",
    "    print(f'Found {num_files} file(s)')\n",
    "    if num_files > 0:\n",
    "        event_file = event_files[-1]\n",
    "        print(f'Processing {event_file}')\n",
    "        event_file_path = os.path.join(target_dir, event_file)\n",
    "        event_acc = event_accumulator.EventAccumulator(event_file_path)\n",
    "        event_acc.Reload()\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "    steps_train, values_train = extract(event_acc, 'train_loss')\n",
    "    steps_valid, values_valid = extract(event_acc, 'val_loss')\n",
    "    steps_epoch, values_epoch = extract(event_acc, 'epoch')\n",
    "    \n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    \n",
    "    ticks_epoch, labels_epoch = (\n",
    "        [float(step) for step in steps_epoch[::cut]][::freq], \n",
    "        [str(int(el)) for el in values_epoch[::cut]][::freq]\n",
    "    )\n",
    "    plt.xticks(ticks_epoch, labels=labels_epoch)\n",
    "    \n",
    "    min_loss = np.floor(np.min(values_train + values_valid))\n",
    "    plt.ylim(1, 3)\n",
    "    \n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.errorbar(steps_train, values_train, color='gray', label='train', marker='s', markersize=4)\n",
    "    plt.errorbar(steps_valid, values_valid, color='xkcd:blue', label='val', marker='s', markersize=4)\n",
    "    plt.axvline(steps_valid[::-1][np.argmin(values_valid[::-1]).item()],\n",
    "                0, (np.min(values_valid)-1)/2,\n",
    "                color='xkcd:blue', linestyle='dashed')\n",
    "    plt.text(steps_valid[::-1][np.argmin(values_valid[::-1]).item()]*1.05, min_loss + 0.1,\n",
    "             'best', color='black')\n",
    "    \n",
    "    plt.legend(loc='upper right')\n",
    "    \n",
    "    if not os.path.isdir(f'{target_dir}/Figures'):\n",
    "        os.mkdir(f'{target_dir}/Figures')\n",
    "        \n",
    "    plt.savefig(f'{target_dir}/Figures/learning_curve.pdf',\n",
    "               format='pdf', bbox_inches='tight')\n",
    "    if show:\n",
    "        plt.gcf().set_dpi(300)\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16076f04",
   "metadata": {},
   "source": [
    "#### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "75b3d121",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Variational AE, not used here\n",
    "# =================================\n",
    "def reparametrize_latent(vae, latent):\n",
    "    mu, log_var = vae.vae_split(latent)\n",
    "    var = np.exp(log_var)\n",
    "\n",
    "    mu, log_var = torch.tensor(mu), torch.tensor(log_var)\n",
    "    sample = vae.vae_reparametrize(mu, log_var).numpy()\n",
    "    return sample\n",
    "# ================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "16f649ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dict_result(trainer, model, dataloader, ckpt_path):\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        trainer.test(model, dataloader, ckpt_path=ckpt_path)\n",
    "    model.test_result[\n",
    "        'labels'\n",
    "    ]=dataloader.dataset.label_enc.inverse_transform(\n",
    "    model.test_result[\n",
    "        'labels'\n",
    "        ].astype(int)\n",
    "    )\n",
    "\n",
    "    real = model.test_result['real'].squeeze()\n",
    "    recon = model.test_result['recon'].squeeze()\n",
    "    weight = model.test_result['weight'].squeeze()\n",
    "\n",
    "\n",
    "    weightedMSE = (real-recon)**2 * weight\n",
    "    pred_errors = (weightedMSE ** 0.5).tolist()\n",
    "\n",
    "    weightedMSE = np.ma.masked_array(data=weightedMSE,\n",
    "                                     mask=~(weight.astype(bool))\n",
    "    )\n",
    "    weightedMSE = weightedMSE.mean(axis=1, keepdims=True)\n",
    "\n",
    "    latent = model.test_result['latent'].copy()\n",
    "    \n",
    "    # For Variational AE, not used here\n",
    "    # =================================\n",
    "    if hasattr(model, 'vae_reparametrize') and callable(model.vae_reparametrize):\n",
    "        # for VAE, we must reparametrize latent first\n",
    "        latent = reparametrize_latent(model, latent)\n",
    "    # =================================\n",
    "    \n",
    "    latentdim = latent.shape[-1]\n",
    "\n",
    "    latent = pd.DataFrame(\n",
    "        data=np.concatenate((latent, weightedMSE), axis=1),\n",
    "        index=model.test_result['labels'],\n",
    "        columns=['feature_'+str(dim) for dim in range(latentdim)]+['wMSE'])\n",
    "\n",
    "    latent.insert(loc=latentdim+1, column='pred_error', value=pred_errors)\n",
    "\n",
    "    return latent, real, recon, weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d6945d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(trainer:L.Trainer, AE:LitAE):\n",
    "    \"\"\"\n",
    "    Creates predictions of a trained AutoEncoder\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    scoring : Akima1DInterpolator (callable)\n",
    "        A function that takes decimal logarithm of the \n",
    "        weighted reconstruction MSE and returns ln of p-value\n",
    "        \n",
    "    df : pd.DataFrame\n",
    "        The resulting scored dataframe\n",
    "    \"\"\"\n",
    "    \n",
    "    # predictions for the augmented training dataset\n",
    "    train_upsampled_latent, real, recon, weight = get_dict_result(\n",
    "        trainer, AE, train_loader, 'best')\n",
    "    \n",
    "    log10wMSE = np.log10(train_upsampled_latent['wMSE'].values).ravel()\n",
    "    # define scoring function using log10[weightedMSE_train] \n",
    "    # and custom KDE (since sklearn KernelDensity calculates \n",
    "    # log-likelihood but not p-value)\n",
    "    \n",
    "    n_samples = log10wMSE.size\n",
    "    SilvermanRuleBandwidth = (4/3/n_samples)**(1/5) * np.std(log10wMSE)\n",
    "\n",
    "    logcdf = lambda x: logsumexp(\n",
    "        log_ndtr(\n",
    "            (x-log10wMSE)/SilvermanRuleBandwidth\n",
    "        ), axis=0, b=1/n_samples\n",
    "    ).item()\n",
    "    \n",
    "    logpvalue = lambda x: logsumexp(\n",
    "        [0.0, logcdf(x)], b=[1.0, -1.0]\n",
    "    )\n",
    "    scoring = np.vectorize(logpvalue)\n",
    "    \n",
    "    log10_wMSE_grid = np.linspace(-3, 3, 10000)\n",
    "    log_pvalue_grid = scoring(log10_wMSE_grid)\n",
    "    \n",
    "    scoring = Akima1DInterpolator(log10_wMSE_grid, log_pvalue_grid)\n",
    "    scoring.extrapolate=True\n",
    "    \n",
    "    # predictions for the non-augmented dataset\n",
    "    train_latent, real, recon, weight = get_dict_result(\n",
    "        trainer, AE, train_loader_, 'best')\n",
    "    val_latent, real, recon, weight = get_dict_result(\n",
    "        trainer, AE, val_loader, 'best')\n",
    "    test_latent, real, recon, weight = get_dict_result(\n",
    "        trainer, AE, test_loader, 'best')\n",
    "    \n",
    "    df = pd.concat(\n",
    "        (train_latent, val_latent, test_latent),\n",
    "        axis=0, ignore_index=False\n",
    "    )\n",
    "    df['sample'] = (\n",
    "        ['train'] * len(train_latent) +\n",
    "        ['val'] * len(val_latent) +\n",
    "        ['test'] * len(test_latent)\n",
    "    )\n",
    "    df['score'] = df['wMSE'].apply(lambda x: np.clip(scoring(np.log10(x)), None, 0.0))\n",
    "    df['p-value'] = df['score'].apply(np.exp)\n",
    "    \n",
    "    return scoring, df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fddbf111",
   "metadata": {},
   "source": [
    "# Training Models & Get Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "87102ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf lightning_logs\n",
    "!rm -rf Architectures\n",
    "!mkdir lightning_logs\n",
    "!mkdir Architectures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f932e606-3a50-4182-a66a-26b99b89a1bb",
   "metadata": {},
   "source": [
    "## *«Standard»* Architecture (32, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bc13d912",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder, decoder, autoencoder, exp_name = create_models(\n",
    "    latent_dim=3, architecture=(32, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4901884e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "early_stopping_callback = EarlyStopping(\n",
    "    monitor='val_loss', mode='min', min_delta=0, patience=20)\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=f'./lightning_logs/{exp_name}',\n",
    "    filename='best', monitor='val_loss', mode='min')\n",
    "\n",
    "logger = TensorBoardLogger(save_dir='./lightning_logs', name=exp_name)\n",
    "\n",
    "trainer = L.Trainer(max_epochs=500, logger=logger,\n",
    "                    callbacks=[checkpoint_callback, early_stopping_callback],\n",
    "                    enable_progress_bar=False\n",
    "                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a51baa-9191-4ed0-bd11-c6ac1c406319",
   "metadata": {},
   "source": [
    "#### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7dc6f9da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-1c80317fa3b1799d\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-1c80317fa3b1799d\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6011;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir lightning_logs/{exp_name} --port 6011"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff1d805",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | encoder | Encoder | 133 K  | train\n",
      "1 | decoder | Decoder | 131 K  | train\n",
      "--------------------------------------------\n",
      "265 K     Trainable params\n",
      "0         Non-trainable params\n",
      "265 K     Total params\n",
      "1.062     Total estimated model params size (MB)\n",
      "36        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(autoencoder, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27bddde1",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_latest_model(exp_name, f'./Architectures/{exp_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d61bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_learning_curve(f'./Architectures/{exp_name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c35de50-e374-43a2-a542-2a9a14870170",
   "metadata": {},
   "source": [
    "#### Get Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ce1535",
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring, df = get_predictions(trainer, autoencoder)\n",
    "df.to_csv(f'./Architectures/{exp_name}/predictions.csv')\n",
    "joblib.dump(scoring, f'./Architectures/{exp_name}/scoring.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead5e9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat((df, labels), axis=1, ignore_index=False)\n",
    "visualize_latent(df,\n",
    "                 title='AutoEncoder Latent Space',\n",
    "                 savedir=f'./Architectures/{exp_name}/Figures',\n",
    "                 show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e228a63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('ROC-AUC Score:'+\n",
    "      '\\n    train : '+\n",
    "      str(round(roc_auc_score(df.loc[train.index, 'FlaresFlag'].values,\n",
    "                              -df.loc[train.index, 'score'].values), 2))+\n",
    "      '\\n    val   : '+\n",
    "      str(round(roc_auc_score(df.loc[val.index, 'FlaresFlag'].values,\n",
    "                              -df.loc[val.index, 'score'].values), 2))+\n",
    "      '\\n    test  : '+\n",
    "      str(round(roc_auc_score(df.loc[test.index, 'FlaresFlag'].values,\n",
    "                              -df.loc[test.index, 'score'].values), 2))\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef60f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler, LinReg = explorer(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72cb0758",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['p-value']<=0.01].sort_values(by='score', axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d408e4d2-1c4a-40f7-a37e-de83138e2ccd",
   "metadata": {},
   "source": [
    "## *«Purblind»* Architecture (16, 4)\n",
    "\n",
    "Reduced number of channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4fbb6c1-d056-433c-9765-a4225cfdb957",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder, decoder, autoencoder, exp_name = create_models(\n",
    "    latent_dim=3, architecture=(16, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed67c9d0-31f9-475c-899e-35b10c99786d",
   "metadata": {},
   "source": [
    "#### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8922c8f-372b-4db4-8d1e-af4602c920eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir lightning_logs/{exp_name} --port 6013"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f583de7-1b46-41e0-8a94-beb9c3747edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_callback = EarlyStopping(\n",
    "    monitor='val_loss', mode='min', min_delta=0, patience=20)\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=f'./lightning_logs/{exp_name}',\n",
    "    filename='best', monitor='val_loss', mode='min')\n",
    "\n",
    "logger = TensorBoardLogger(save_dir='./lightning_logs', name=exp_name)\n",
    "\n",
    "trainer = L.Trainer(max_epochs=500, logger=logger,\n",
    "                    callbacks=[checkpoint_callback, early_stopping_callback],\n",
    "                    enable_progress_bar=False\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c987cf2-69fc-41ef-ab2b-22b077d9a0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(autoencoder, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11079cb5-b392-4f28-a587-88424c4e78ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_latest_model(exp_name, f'./Architectures/{exp_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274e09ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_learning_curve(f'./Architectures/{exp_name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec37e98f-299e-4424-ba09-271e77953558",
   "metadata": {},
   "source": [
    "#### Get Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e564fea8-3cda-404c-aece-26a793b1dcbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring, df = get_predictions(trainer, autoencoder)\n",
    "df.to_csv(f'./Architectures/{exp_name}/predictions.csv')\n",
    "joblib.dump(scoring, f'./Architectures/{exp_name}/scoring.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f209d9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat((df, labels), axis=1, ignore_index=False)\n",
    "visualize_latent(df,\n",
    "                 title='AutoEncoder Latent Space',\n",
    "                 savedir=f'./Architectures/{exp_name}/Figures',\n",
    "                 show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732ba84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('ROC-AUC Score:'+\n",
    "      '\\n    train : '+\n",
    "      str(round(roc_auc_score(df.loc[train.index, 'FlaresFlag'].values,\n",
    "                              -df.loc[train.index, 'score'].values), 2))+\n",
    "      '\\n    val   : '+\n",
    "      str(round(roc_auc_score(df.loc[val.index, 'FlaresFlag'].values,\n",
    "                              -df.loc[val.index, 'score'].values), 2))+\n",
    "      '\\n    test  : '+\n",
    "      str(round(roc_auc_score(df.loc[test.index, 'FlaresFlag'].values,\n",
    "                              -df.loc[test.index, 'score'].values), 2))\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375daee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler, LinReg = explorer(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2322b427",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['p-value']<=0.01].sort_values(by='score', axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18985c6d-8312-4d97-9f1e-bcb54615d8ed",
   "metadata": {},
   "source": [
    "## *«Shallow»* Architecture (32, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e78eb1-bd0d-46fe-af51-752fc3fe6a3e",
   "metadata": {},
   "source": [
    "Reduced depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29afc0f-70ed-4843-a7c4-f10a14ec92ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder, decoder, autoencoder, exp_name = create_models(\n",
    "    latent_dim=3, architecture=(32, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a3f1fd-4cb7-4df5-97c7-627807db4309",
   "metadata": {},
   "source": [
    "#### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a14030-6711-4202-951c-b29be9d8f5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir lightning_logs/{exp_name} --port 6015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e437265-64c8-4f05-9cd8-0bc36b351852",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_callback = EarlyStopping(\n",
    "    monitor='val_loss', mode='min', min_delta=0, patience=20)\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=f'./lightning_logs/{exp_name}',\n",
    "    filename='best', monitor='val_loss', mode='min')\n",
    "\n",
    "logger = TensorBoardLogger(save_dir='./lightning_logs', name=exp_name)\n",
    "\n",
    "trainer = L.Trainer(max_epochs=500, logger=logger,\n",
    "                    callbacks=[checkpoint_callback, early_stopping_callback],\n",
    "                    enable_progress_bar=False\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6274b2ad-5191-4642-89dd-14f09742da97",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(autoencoder, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91add9e2-0519-482d-bcd2-882e4550e436",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_latest_model(exp_name, f'./Architectures/{exp_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7d83cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_learning_curve(f'./Architectures/{exp_name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2d7602-d0c6-440a-9518-803d35b8ab78",
   "metadata": {},
   "source": [
    "#### Get Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2630434b-6858-4950-aec0-4e00fccc8a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring, df = get_predictions(trainer, autoencoder)\n",
    "df.to_csv(f'./Architectures/{exp_name}/predictions.csv')\n",
    "joblib.dump(scoring, f'./Architectures/{exp_name}/scoring.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059c887a-e4b0-413a-a3dd-50c0bae38594",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat((df, labels), axis=1, ignore_index=False)\n",
    "visualize_latent(df,\n",
    "                 title='AutoEncoder Latent Space',\n",
    "                 savedir=f'./Architectures/{exp_name}/Figures',\n",
    "                 show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5f3571",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('ROC-AUC Score:'+\n",
    "      '\\n    train : '+\n",
    "      str(round(roc_auc_score(df.loc[train.index, 'FlaresFlag'].values,\n",
    "                              -df.loc[train.index, 'score'].values), 2))+\n",
    "      '\\n    val   : '+\n",
    "      str(round(roc_auc_score(df.loc[val.index, 'FlaresFlag'].values,\n",
    "                              -df.loc[val.index, 'score'].values), 2))+\n",
    "      '\\n    test  : '+\n",
    "      str(round(roc_auc_score(df.loc[test.index, 'FlaresFlag'].values,\n",
    "                              -df.loc[test.index, 'score'].values), 2))\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abe0b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler, LinReg = explorer(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99730674",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['p-value']<=0.01].sort_values(by='score', axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14832d1-2c3c-4d43-8222-56af393ea6f6",
   "metadata": {},
   "source": [
    "## *«Tiny»* Architecture (16, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c19f08-bd0d-47b3-b3f5-279d3d45d8a7",
   "metadata": {},
   "source": [
    "Reduced both number of channels & depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce0480b-5adf-45f1-be6e-376590a12d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder, decoder, autoencoder, exp_name = create_models(\n",
    "    latent_dim=3, architecture=(16, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7768ac-ac05-4306-9fd9-3fc476c88b94",
   "metadata": {},
   "source": [
    "#### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9628a4-0054-430b-98b4-1ce84872582d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir lightning_logs/{exp_name} --port 6017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9dc9b9a-685d-41e7-a4f9-3b0a03c487bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_callback = EarlyStopping(\n",
    "    monitor='val_loss', mode='min', min_delta=0, patience=20)\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=f'./lightning_logs/{exp_name}',\n",
    "    filename='best', monitor='val_loss', mode='min')\n",
    "\n",
    "logger = TensorBoardLogger(save_dir='./lightning_logs', name=exp_name)\n",
    "\n",
    "trainer = L.Trainer(max_epochs=500, logger=logger,\n",
    "                    callbacks=[checkpoint_callback, early_stopping_callback],\n",
    "                    enable_progress_bar=False\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d15a81-5d62-4b89-a0fe-dcc6de139a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(autoencoder, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f1b51d-4107-43e1-9e13-c18181bdab91",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_latest_model(exp_name, f'./Architectures/{exp_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f139eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_learning_curve(f'./Architectures/{exp_name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e90a49-e920-45d8-a94e-062a81b42d50",
   "metadata": {},
   "source": [
    "#### Get Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49268116-f30f-46c7-a963-08b164e66bd4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scoring, df = get_predictions(trainer, autoencoder)\n",
    "df.to_csv(f'./Architectures/{exp_name}/predictions.csv')\n",
    "\n",
    "joblib.dump(scoring, f'./Architectures/{exp_name}/scoring.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216739b9-5f70-4957-a3b2-a3a9523d873c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.concat((df, labels), axis=1, ignore_index=False)\n",
    "visualize_latent(df,\n",
    "                 title='AutoEncoder Latent Space',\n",
    "                 savedir=f'./Architectures/{exp_name}/Figures',\n",
    "                 show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4cdf5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('ROC-AUC Score:'+\n",
    "      '\\n    train : '+\n",
    "      str(round(roc_auc_score(df.loc[train.index, 'FlaresFlag'].values,\n",
    "                              -df.loc[train.index, 'score'].values), 2))+\n",
    "      '\\n    val   : '+\n",
    "      str(round(roc_auc_score(df.loc[val.index, 'FlaresFlag'].values,\n",
    "                              -df.loc[val.index, 'score'].values), 2))+\n",
    "      '\\n    test  : '+\n",
    "      str(round(roc_auc_score(df.loc[test.index, 'FlaresFlag'].values,\n",
    "                              -df.loc[test.index, 'score'].values), 2))\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f17218",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler, LinReg = explorer(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b7c520",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['p-value']<=0.01].sort_values(by='score', axis=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
