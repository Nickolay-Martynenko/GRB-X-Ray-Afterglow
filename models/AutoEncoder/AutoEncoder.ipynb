{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce4d063c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import sys\n",
    "\n",
    "from collections import defaultdict\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchmetrics\n",
    "\n",
    "import lightning as L\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c06e73e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc8374bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilities.data_downloader import train_val_test_downloader\n",
    "from utilities.upsampling import upsampling\n",
    "from utilities.plots import plt, COLORMAP, visualize_latent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c0b03a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from warnings import simplefilter\n",
    "simplefilter(\"ignore\", category=RuntimeWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e7fd637",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def set_random_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "set_random_seed(42)\n",
    "L.seed_everything(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa72713",
   "metadata": {},
   "source": [
    "# Description\n",
    "\n",
    "bla bla"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5b8852",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "bla bla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d0126d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets downloaded\n",
      " - train  : 810 entries\n",
      " - val    : 174 entries\n",
      " - test   : 174 entries\n",
      " - labels : 1158 entries\n"
     ]
    }
   ],
   "source": [
    "train, val, test, labels = train_val_test_downloader('interp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60ec389c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_upsampled = upsampling(train)\n",
    "len(train_upsampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "466277ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LightCurveDataset(Dataset):\n",
    "    def __init__(self, dataframe:pd.DataFrame,\n",
    "                 data_col:str='lgRate',\n",
    "                 weight_col:str='weight'):\n",
    "        \n",
    "        data = np.array(dataframe.loc[:, data_col].tolist(),\n",
    "                        dtype=np.float32)\n",
    "        weight = np.array(dataframe.loc[:, weight_col].tolist(),\n",
    "                          dtype=np.float32)\n",
    "        \n",
    "        self.data = torch.from_numpy(\n",
    "            data).unsqueeze(dim=1)   # value\n",
    "        self.weight = torch.from_numpy(\n",
    "            weight).unsqueeze(dim=1) # weight\n",
    "\n",
    "        # using dataframe index = event names \n",
    "        # as labels\n",
    "        labels = dataframe.index\n",
    "        self.label_enc = LabelEncoder()\n",
    "        self.labels = torch.as_tensor(self.label_enc.fit_transform(labels))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx], self.weight[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b1d85aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, val_dataset, test_dataset = (\n",
    "    LightCurveDataset(train_upsampled),\n",
    "    LightCurveDataset(val),\n",
    "    LightCurveDataset(test)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "05e5eeed",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset,\n",
    "                          batch_size=32,\n",
    "                          shuffle=True,\n",
    "                          num_workers=0)\n",
    "val_loader = DataLoader(val_dataset,\n",
    "                        batch_size=32,\n",
    "                        shuffle=False,\n",
    "                        num_workers=0)\n",
    "test_loader = DataLoader(test_dataset,\n",
    "                         batch_size=32,\n",
    "                         shuffle=False,\n",
    "                         num_workers=0)\n",
    "\n",
    "# for predictions on non-augmented train:\n",
    "train_loader_ = DataLoader(LightCurveDataset(train),\n",
    "                           batch_size=32,\n",
    "                           shuffle=False,\n",
    "                           num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae2b77d",
   "metadata": {},
   "source": [
    "# Model\n",
    "bla bla"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9489383f",
   "metadata": {},
   "source": [
    "## Torch Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "290613ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, latent_dim:int,\n",
    "                 architecture:tuple=(32, 4),\n",
    "                 tseries_length:int=64):\n",
    "        super().__init__()\n",
    "\n",
    "        self.hidden_dims = [\n",
    "            architecture[0]* 2**pow for pow in range(architecture[1])\n",
    "            ]                                       # num of filters in layers\n",
    "        self.tseries_length = tseries_length\n",
    "\n",
    "        modules = []\n",
    "        in_channels = 1                             # initial num of channels\n",
    "        for h_dim in self.hidden_dims:              # conv layers\n",
    "            modules.append(\n",
    "                nn.Sequential(\n",
    "                    nn.Conv1d(\n",
    "                        in_channels=in_channels,    # num of input channels\n",
    "                        out_channels=h_dim,         # num of output channels\n",
    "                        kernel_size=3,\n",
    "                        stride=2,                   # convolution kernel step\n",
    "                        padding=1,                  # save shape\n",
    "                    ),\n",
    "                    nn.BatchNorm1d(h_dim),\n",
    "                    nn.LeakyReLU(),\n",
    "                )\n",
    "            )\n",
    "            in_channels = h_dim                     # changing num of \n",
    "                                                    # input channels for \n",
    "                                                    # next iteration\n",
    "\n",
    "        modules.append(nn.Flatten())                # to vector\n",
    "        intermediate_dim = (\n",
    "            self.hidden_dims[-1] * \n",
    "            self.tseries_length // (2**len(self.hidden_dims))\n",
    "        )\n",
    "        modules.append(nn.Linear(in_features=intermediate_dim,\n",
    "                                 out_features=latent_dim))\n",
    "\n",
    "        self.encoder = nn.Sequential(*modules)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, latent_dim:int,\n",
    "                 architecture:tuple=(32, 4),\n",
    "                 tseries_length:int=64):\n",
    "        super().__init__()\n",
    "        self.hidden_dims = [\n",
    "            architecture[0]* 2**pow for pow in range(architecture[1]-1, 0, -1)\n",
    "            ]                                       # num of filters in layers\n",
    "        self.tseries_length = tseries_length\n",
    "\n",
    "        intermediate_dim = (\n",
    "            self.hidden_dims[0] * \n",
    "            self.tseries_length // (2**len(self.hidden_dims))\n",
    "        )\n",
    "        self.linear = nn.Linear(in_features=latent_dim,\n",
    "                                out_features=intermediate_dim)\n",
    "\n",
    "        modules = []\n",
    "        for i in range(len(self.hidden_dims) - 1):  # define upsample layers\n",
    "            modules.append(\n",
    "                nn.Sequential(\n",
    "                    nn.Upsample(scale_factor=2),\n",
    "                    nn.Conv1d(\n",
    "                        in_channels=self.hidden_dims[i],\n",
    "                        out_channels=self.hidden_dims[i + 1],\n",
    "                        kernel_size=3,\n",
    "                        padding=1,\n",
    "                    ),\n",
    "                    nn.BatchNorm1d(self.hidden_dims[i + 1]),\n",
    "                    nn.LeakyReLU(),\n",
    "                )\n",
    "            )\n",
    "\n",
    "        modules.append(\n",
    "            nn.Sequential(\n",
    "                nn.Upsample(scale_factor=2),\n",
    "                nn.Conv1d(in_channels=self.hidden_dims[-1],\n",
    "                          out_channels=1,\n",
    "                          kernel_size=3, padding=1)\n",
    "            )\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(*modules)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)        # from latents space to Linear\n",
    "        x = x.view(\n",
    "            -1, self.hidden_dims[0],\n",
    "            self.tseries_length // (2**len(self.hidden_dims))\n",
    "            )                     # reshape\n",
    "        x = self.decoder(x)       # reconstruction\n",
    "        return x\n",
    "\n",
    "class VAEncoder(Encoder):\n",
    "    def __init__(self, latent_dim):\n",
    "        if latent_dim % 2 != 0:   # check for the parity of the latent space\n",
    "            raise Exception('Latent size for VAEncoder must be even')\n",
    "\n",
    "        super().__init__(latent_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902b372b",
   "metadata": {},
   "source": [
    "## Lightning wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fce0b3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LitAE(L.LightningModule):\n",
    "    def __init__(self, encoder, decoder, derivative_weight=1.0):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.derivative_weight = derivative_weight\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=1e-4)\n",
    "\n",
    "    def forward_handler(self, data,\n",
    "                        *args, **kwargs):\n",
    "        # here is the logic how data is moved through AE\n",
    "        latent = self.encoder(data)\n",
    "        recon = self.decoder(latent)\n",
    "        return latent, recon\n",
    "\n",
    "    def loss_handler(self, recon, data, weight, latent,\n",
    "                     *args, **kwargs):\n",
    "        # here is the loss function computing\n",
    "        recon_loss = torch.masked_select(\n",
    "            input = F.mse_loss(\n",
    "                recon, data, reduction='none'\n",
    "            ) * weight,\n",
    "            mask = weight.ge(0.0)\n",
    "        )\n",
    "        recon_loss = recon_loss.mean()\n",
    "\n",
    "        # derivative penalty = \n",
    "        # L1-regularization of the output timeseries\n",
    "        derivative_loss = torch.abs(\n",
    "            torch.diff(recon, dim=-1)\n",
    "        ).mean()\n",
    "\n",
    "        # total loss\n",
    "        loss = recon_loss + self.derivative_weight * derivative_loss\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        data, labels, weight = batch\n",
    "\n",
    "        latent, recon = self.forward_handler(data, labels)\n",
    "        loss = self.loss_handler(recon, data, weight, latent)\n",
    "\n",
    "        self.log('train_loss', loss, on_step=False, on_epoch=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        data, labels, weight = batch\n",
    "\n",
    "        latent, recon = self.forward_handler(data, labels)\n",
    "        loss = self.loss_handler(recon, data, weight, latent)\n",
    "\n",
    "        self.log('val_loss', loss, on_step=False, on_epoch=True)\n",
    "        return loss\n",
    "\n",
    "    def on_test_epoch_start(self):\n",
    "        # create dict with empty tensors for further accumulating over batches\n",
    "        self.test_result = defaultdict(torch.Tensor)\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        data, labels, weight = batch\n",
    "\n",
    "        latent, recon = self.forward_handler(data, labels)\n",
    "        self.update_test_result(data, weight, recon, latent, labels)\n",
    "\n",
    "    def update_test_result(self, data, weight, recon, latent, labels):\n",
    "        # accumulating results every batch\n",
    "        self.test_result['real'] = torch.cat(\n",
    "            [self.test_result['real'], data.cpu()]\n",
    "        )\n",
    "        self.test_result['weight'] = torch.cat(\n",
    "            [self.test_result['weight'], weight.cpu()]\n",
    "        )\n",
    "        self.test_result['recon'] = torch.cat(\n",
    "            [self.test_result['recon'], recon.cpu()]\n",
    "        )\n",
    "        self.test_result['latent'] = torch.cat(\n",
    "            [self.test_result['latent'], latent.cpu()]\n",
    "        )\n",
    "        self.test_result['labels'] = torch.cat(\n",
    "            [self.test_result['labels'], labels.cpu()]\n",
    "        )\n",
    "\n",
    "    def on_test_epoch_end(self):\n",
    "        # simply change type from torch tensor to numpy array\n",
    "        # for every item in test_result dictionary\n",
    "        for key in self.test_result:\n",
    "            self.test_result[key] = self.test_result[key].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "95e26cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LitVAE(LitAE):\n",
    "    def __init__(self, encoder, decoder,\n",
    "                 derivative_weight=1.0,\n",
    "                 kld_weight=0.005,\n",
    "                 ):\n",
    "        super().__init__(encoder, decoder, derivative_weight)\n",
    "        self.kld_weight = kld_weight\n",
    "\n",
    "    def vae_split(self, latent):\n",
    "        size = (\n",
    "            latent.shape[1] // 2\n",
    "        )  # divide the latent representation into mu and log_var\n",
    "        mu = latent[:, :size]\n",
    "        log_var = latent[:, size:]\n",
    "        return mu, log_var\n",
    "\n",
    "    def vae_reparametrize(self, mu, log_var):\n",
    "        sigma = torch.exp(0.5 * log_var)\n",
    "        eps = torch.randn(mu.shape[0], mu.shape[1]).to(self.device)\n",
    "        return eps * sigma + mu\n",
    "\n",
    "    def kld_loss(self, mu, log_var):\n",
    "        var = log_var.exp()\n",
    "        kl_loss = torch.mean(\n",
    "            -0.5 * torch.sum(log_var - var - mu**2 + 1, dim=1), dim=0\n",
    "        )\n",
    "        return kl_loss\n",
    "\n",
    "    def forward_handler(self, data, *args, **kwargs):\n",
    "        # here is the logic how data is moved through AE\n",
    "        latent = self.encoder(data)\n",
    "\n",
    "        mu, log_var = self.vae_split(latent)\n",
    "        sample = self.vae_reparametrize(mu, log_var)\n",
    "\n",
    "        recon = self.decoder(sample)\n",
    "        return latent, recon\n",
    "\n",
    "    def loss_handler(self, recon, data, weight, latent, *args, **kwargs):\n",
    "        mu, log_var = self.vae_split(latent)\n",
    "        # here is the loss function computing\n",
    "        loss = torch.masked_select(\n",
    "            input = F.mse_loss(recon, data, reduction='none') * weight,\n",
    "            mask = weight.ge(0.0)).mean() + self.derivative_weight * torch.abs(\n",
    "            torch.diff(recon, dim=-1)\n",
    "            ).mean() + self.kld_weight * self.kld_loss(mu, log_var)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073c03ae",
   "metadata": {},
   "source": [
    "## Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "75b3d121",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reparametrize_latent(vae, latent):\n",
    "    mu, log_var = vae.vae_split(latent)\n",
    "    var = np.exp(log_var)\n",
    "\n",
    "    mu, log_var = torch.tensor(mu), torch.tensor(log_var)\n",
    "    sample = vae.vae_reparametrize(mu, log_var).numpy()\n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "16f649ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dict_result(trainer, model, dataloader, ckpt_path):\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        trainer.test(model, dataloader, ckpt_path=ckpt_path)\n",
    "    model.test_result[\n",
    "        'labels'\n",
    "    ]=dataloader.dataset.label_enc.inverse_transform(\n",
    "    model.test_result[\n",
    "        'labels'\n",
    "        ].astype(int)\n",
    "    )\n",
    "\n",
    "    real = model.test_result['real'].squeeze()\n",
    "    recon = model.test_result['recon'].squeeze()\n",
    "    weight = model.test_result['weight'].squeeze()\n",
    "\n",
    "\n",
    "    weightedMSE = (real-recon)**2 * weight\n",
    "    pred_errors = (weightedMSE ** 0.5).tolist()\n",
    "\n",
    "    weightedMSE = np.ma.masked_array(data=weightedMSE,\n",
    "                                     mask=~(weight.astype(bool))\n",
    "    )\n",
    "    weightedMSE = weightedMSE.mean(axis=1, keepdims=True)\n",
    "\n",
    "    latent = model.test_result['latent'].copy()\n",
    "\n",
    "    if hasattr(model, 'vae_reparametrize') and callable(model.vae_reparametrize):\n",
    "        # for VAE, we must reparametrize latent first\n",
    "        latent = reparametrize_latent(model, latent)\n",
    "\n",
    "    latentdim = latent.shape[-1]\n",
    "\n",
    "    latent = pd.DataFrame(\n",
    "        data=np.concatenate((latent, weightedMSE), axis=1),\n",
    "        index=model.test_result['labels'],\n",
    "        columns=['feature_'+str(dim) for dim in range(latentdim)]+['wMSE'])\n",
    "\n",
    "    latent.insert(loc=latent_dim+1, column='pred_error', value=pred_errors)\n",
    "\n",
    "    return latent, real, recon, weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fddbf111",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bc13d912",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 3\n",
    "\n",
    "encoder, decoder = Encoder(latent_dim), Decoder(latent_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "89f19554",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Encoder(\n",
       "  (encoder): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Conv1d(1, 32, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "      (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Conv1d(32, 64, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "      (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Conv1d(64, 128, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): Conv1d(128, 256, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (4): Flatten(start_dim=1, end_dim=-1)\n",
       "    (5): Linear(in_features=1024, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fccda5a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Decoder(\n",
       "  (linear): Linear(in_features=3, out_features=2048, bias=True)\n",
       "  (decoder): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Upsample(scale_factor=2.0, mode='nearest')\n",
       "      (1): Conv1d(256, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Upsample(scale_factor=2.0, mode='nearest')\n",
       "      (1): Conv1d(128, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Upsample(scale_factor=2.0, mode='nearest')\n",
       "      (1): Conv1d(64, 1, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8fde4f85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoEncoder.ipynb requirements.txt\r\n"
     ]
    }
   ],
   "source": [
    "!rm -rf lightning_logs\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "87102ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir lightning_logs\n",
    "!mkdir lightning_logs/AE_latent_dim={latent_dim}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7dc6f9da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6010 (pid 99622), started 1:09:01 ago. (Use '!kill 99622' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-1c80317fa3b1799d\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-1c80317fa3b1799d\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6010;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir lightning_logs/AE_latent_dim={latent_dim} --port 6010"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e7715518",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "autoencoder = LitAE(encoder, decoder)\n",
    "\n",
    "exp_name = f'AE_latent_dim={latent_dim}'\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=f'./lightning_logs/AE_latent_dim={latent_dim}',\n",
    "    filename='best', monitor='val_loss', mode='min')\n",
    "\n",
    "early_stopping_callback = EarlyStopping(\n",
    "    monitor='val_loss', mode='min', min_delta=0, patience=50)\n",
    "\n",
    "logger = TensorBoardLogger(save_dir='./lightning_logs', name=exp_name)\n",
    "\n",
    "trainer = L.Trainer(max_epochs=500, logger=logger,\n",
    "                    callbacks=[checkpoint_callback, early_stopping_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff1d805",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nickolaymartynenko/anaconda3/lib/python3.11/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /Users/nickolaymartynenko/Downloads/GRB-X-Ray-Afterglow/models/AutoEncoder/lightning_logs/AE_latent_dim=3 exists and is not empty.\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | encoder | Encoder | 133 K  | train\n",
      "1 | decoder | Decoder | 131 K  | train\n",
      "--------------------------------------------\n",
      "265 K     Trainable params\n",
      "0         Non-trainable params\n",
      "265 K     Total params\n",
      "1.062     Total estimated model params size (MB)\n",
      "36        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87ec2d1560924de5842b3ef03bf479a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |                                        | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.fit(autoencoder, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2bb6836",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27bddde1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
