{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e00dda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import sys\n",
    "\n",
    "from collections import defaultdict\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchmetrics\n",
    "from torchsummary import summary\n",
    "\n",
    "import lightning as L\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca41f185",
   "metadata": {},
   "outputs": [],
   "source": [
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a67dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilities.data_downloader import train_val_test_downloader\n",
    "from utilities.upsampling import upsampling\n",
    "from utilities.plots import plt, COLORMAP, visualize_latent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbecf013",
   "metadata": {},
   "outputs": [],
   "source": [
    "from warnings import simplefilter\n",
    "simplefilter(\"ignore\", category=RuntimeWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55ad673",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_random_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "set_random_seed(42)\n",
    "L.seed_everything(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae838fc",
   "metadata": {},
   "source": [
    "# Description\n",
    "\n",
    "bla bla"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b55ffe38",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "bla bla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f915e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val, test, labels = train_val_test_downloader('interp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8887e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_upsampled = upsampling(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3dcb1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LightCurveDataset(Dataset):\n",
    "    def __init__(self, dataframe:pd.DataFrame,\n",
    "                 data_col:str='lgRate',\n",
    "                 weight_col:str='weight'):\n",
    "        \n",
    "        data = np.array(dataframe.loc[:, data_col].tolist(),\n",
    "                        dtype=np.float32)\n",
    "        weight = np.array(dataframe.loc[:, weight_col].tolist(),\n",
    "                          dtype=np.float32)\n",
    "        \n",
    "        self.data = torch.from_numpy(\n",
    "            data).unsqueeze(dim=1)   # value\n",
    "        self.weight = torch.from_numpy(\n",
    "            weight).unsqueeze(dim=1) # weight\n",
    "\n",
    "        # using dataframe index = event names \n",
    "        # as labels\n",
    "        labels = dataframe.index\n",
    "        self.label_enc = LabelEncoder()\n",
    "        self.labels = torch.as_tensor(self.label_enc.fit_transform(labels))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx], self.weight[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520431a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, val_dataset, test_dataset = (\n",
    "    LightCurveDataset(train_upsampled),\n",
    "    LightCurveDataset(val),\n",
    "    LightCurveDataset(test)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23656867",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset,\n",
    "                          batch_size=256,\n",
    "                          shuffle=True,\n",
    "                          num_workers=2)\n",
    "val_loader = DataLoader(val_dataset,\n",
    "                        batch_size=256,\n",
    "                        shuffle=False,\n",
    "                        num_workers=2)\n",
    "test_loader = DataLoader(test_dataset,\n",
    "                         batch_size=256,\n",
    "                         shuffle=False,\n",
    "                         num_workers=2)\n",
    "\n",
    "# for predictions on non-augmented train:\n",
    "train_loader_ = DataLoader(LightCurveDataset(train),\n",
    "                           batch_size=256,\n",
    "                           shuffle=False,\n",
    "                           num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fbfacfe",
   "metadata": {},
   "source": [
    "# Model\n",
    "bla bla"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b265a2fc",
   "metadata": {},
   "source": [
    "## Torch Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a679cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, latent_dim:int,\n",
    "                 architecture:tuple=(32, 4),\n",
    "                 tseries_length:int=64):\n",
    "        super().__init__()\n",
    "\n",
    "        self.hidden_dims = [\n",
    "            architecture[0]* 2**pow for pow in range(architecture[1])\n",
    "            ]                                       # num of filters in layers\n",
    "        self.tseries_length = tseries_length\n",
    "\n",
    "        modules = []\n",
    "        in_channels = 1                             # initial num of channels\n",
    "        for h_dim in self.hidden_dims:              # conv layers\n",
    "            modules.append(\n",
    "                nn.Sequential(\n",
    "                    nn.Conv1d(\n",
    "                        in_channels=in_channels,    # num of input channels\n",
    "                        out_channels=h_dim,         # num of output channels\n",
    "                        kernel_size=3,\n",
    "                        stride=2,                   # convolution kernel step\n",
    "                        padding=1,                  # save shape\n",
    "                    ),\n",
    "                    nn.BatchNorm1d(h_dim),\n",
    "                    nn.LeakyReLU(),\n",
    "                )\n",
    "            )\n",
    "            in_channels = h_dim                     # changing num of \n",
    "                                                    # input channels for \n",
    "                                                    # next iteration\n",
    "\n",
    "        modules.append(nn.Flatten())                # to vector\n",
    "        intermediate_dim = (\n",
    "            self.hidden_dims[-1] * \n",
    "            self.tseries_length // (2**len(self.hidden_dims))\n",
    "        )\n",
    "        modules.append(nn.Linear(in_features=intermediate_dim,\n",
    "                                 out_features=latent_dim))\n",
    "\n",
    "        self.encoder = nn.Sequential(*modules)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, latent_dim:int,\n",
    "                 architecture:tuple=(32, 4),\n",
    "                 tseries_length:int=64):\n",
    "        super().__init__()\n",
    "        self.hidden_dims = [\n",
    "            architecture[0]* 2**pow for pow in range(architecture[1]-1, 0, -1)\n",
    "            ]                                       # num of filters in layers\n",
    "        self.tseries_length = tseries_length\n",
    "\n",
    "        intermediate_dim = (\n",
    "            self.hidden_dims[0] * \n",
    "            self.tseries_length // (2**len(self.hidden_dims))\n",
    "        )\n",
    "        self.linear = nn.Linear(in_features=latent_dim,\n",
    "                                out_features=intermediate_dim)\n",
    "\n",
    "        modules = []\n",
    "        for i in range(len(self.hidden_dims) - 1):  # define upsample layers\n",
    "            modules.append(\n",
    "                nn.Sequential(\n",
    "                    nn.Upsample(scale_factor=2),\n",
    "                    nn.Conv1d(\n",
    "                        in_channels=self.hidden_dims[i],\n",
    "                        out_channels=self.hidden_dims[i + 1],\n",
    "                        kernel_size=3,\n",
    "                        padding=1,\n",
    "                    ),\n",
    "                    nn.BatchNorm1d(self.hidden_dims[i + 1]),\n",
    "                    nn.LeakyReLU(),\n",
    "                )\n",
    "            )\n",
    "\n",
    "        modules.append(\n",
    "            nn.Sequential(\n",
    "                nn.Upsample(scale_factor=2),\n",
    "                nn.Conv1d(in_channels=self.hidden_dims[-1],\n",
    "                          out_channels=1,\n",
    "                          kernel_size=3, padding=1)\n",
    "            )\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(*modules)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)        # from latents space to Linear\n",
    "        x = x.view(\n",
    "            -1, self.hidden_dims[0],\n",
    "            self.tseries_length // (2**len(self.hidden_dims))\n",
    "            )                     # reshape\n",
    "        x = self.decoder(x)       # reconstruction\n",
    "        return x\n",
    "\n",
    "class VAEncoder(Encoder):\n",
    "    def __init__(self, latent_dim):\n",
    "        if latent_dim % 2 != 0:   # check for the parity of the latent space\n",
    "            raise Exception('Latent size for VAEncoder must be even')\n",
    "\n",
    "        super().__init__(latent_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "701ca605",
   "metadata": {},
   "source": [
    "## Lightning wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf723c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LitAE(L.LightningModule):\n",
    "    def __init__(self, encoder, decoder, derivative_weight=1.0):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.derivative_weight = derivative_weight\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=1e-4)\n",
    "\n",
    "    def forward_handler(self, data,\n",
    "                        *args, **kwargs):\n",
    "        # here is the logic how data is moved through AE\n",
    "        latent = self.encoder(data)\n",
    "        recon = self.decoder(latent)\n",
    "        return latent, recon\n",
    "\n",
    "    def loss_handler(self, recon, data, weight, latent,\n",
    "                     *args, **kwargs):\n",
    "        # here is the loss function computing\n",
    "        recon_loss = torch.masked_select(\n",
    "            input = F.mse_loss(\n",
    "                recon, data, reduction='none'\n",
    "            ) * weight,\n",
    "            mask = weight.ge(0.0)\n",
    "        )\n",
    "        recon_loss = recon_loss.mean()\n",
    "\n",
    "        # derivative penalty = \n",
    "        # L1-regularization of the output timeseries\n",
    "        derivative_loss = torch.abs(\n",
    "            torch.diff(recon, dim=-1)\n",
    "        ).mean()\n",
    "\n",
    "        # total loss\n",
    "        loss = recon_loss + self.derivative_weight * derivative_loss\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        data, labels, weight = batch\n",
    "\n",
    "        latent, recon = self.forward_handler(data, labels)\n",
    "        loss = self.loss_handler(recon, data, weight, latent)\n",
    "\n",
    "        self.log('train_loss', loss, on_step=False, on_epoch=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        data, labels, weight = batch\n",
    "\n",
    "        latent, recon = self.forward_handler(data, labels)\n",
    "        loss = self.loss_handler(recon, data, weight, latent)\n",
    "\n",
    "        self.log('val_loss', loss, on_step=False, on_epoch=True)\n",
    "        return loss\n",
    "\n",
    "    def on_test_epoch_start(self):\n",
    "        # create dict with empty tensors for further accumulating over batches\n",
    "        self.test_result = defaultdict(torch.Tensor)\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        data, labels, weight = batch\n",
    "\n",
    "        latent, recon = self.forward_handler(data, labels)\n",
    "        self.update_test_result(data, weight, recon, latent, labels)\n",
    "\n",
    "    def update_test_result(self, data, weight, recon, latent, labels):\n",
    "        # accumulating results every batch\n",
    "        self.test_result['real'] = torch.cat(\n",
    "            [self.test_result['real'], data.cpu()]\n",
    "        )\n",
    "        self.test_result['weight'] = torch.cat(\n",
    "            [self.test_result['weight'], weight.cpu()]\n",
    "        )\n",
    "        self.test_result['recon'] = torch.cat(\n",
    "            [self.test_result['recon'], recon.cpu()]\n",
    "        )\n",
    "        self.test_result['latent'] = torch.cat(\n",
    "            [self.test_result['latent'], latent.cpu()]\n",
    "        )\n",
    "        self.test_result['labels'] = torch.cat(\n",
    "            [self.test_result['labels'], labels.cpu()]\n",
    "        )\n",
    "\n",
    "    def on_test_epoch_end(self):\n",
    "        # simply change type from torch tensor to numpy array\n",
    "        # for every item in test_result dictionary\n",
    "        for key in self.test_result:\n",
    "            self.test_result[key] = self.test_result[key].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c689c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LitVAE(LitAE):\n",
    "    def __init__(self, encoder, decoder,\n",
    "                 derivative_weight=1.0,\n",
    "                 kld_weight=0.005,\n",
    "                 ):\n",
    "        super().__init__(encoder, decoder, derivative_weight)\n",
    "        self.kld_weight = kld_weight\n",
    "\n",
    "    def vae_split(self, latent):\n",
    "        size = (\n",
    "            latent.shape[1] // 2\n",
    "        )  # divide the latent representation into mu and log_var\n",
    "        mu = latent[:, :size]\n",
    "        log_var = latent[:, size:]\n",
    "        return mu, log_var\n",
    "\n",
    "    def vae_reparametrize(self, mu, log_var):\n",
    "        sigma = torch.exp(0.5 * log_var)\n",
    "        eps = torch.randn(mu.shape[0], mu.shape[1]).to(self.device)\n",
    "        return eps * sigma + mu\n",
    "\n",
    "    def kld_loss(self, mu, log_var):\n",
    "        var = log_var.exp()\n",
    "        kl_loss = torch.mean(\n",
    "            -0.5 * torch.sum(log_var - var - mu**2 + 1, dim=1), dim=0\n",
    "        )\n",
    "        return kl_loss\n",
    "\n",
    "    def forward_handler(self, data, *args, **kwargs):\n",
    "        # here is the logic how data is moved through AE\n",
    "        latent = self.encoder(data)\n",
    "\n",
    "        mu, log_var = self.vae_split(latent)\n",
    "        sample = self.vae_reparametrize(mu, log_var)\n",
    "\n",
    "        recon = self.decoder(sample)\n",
    "        return latent, recon\n",
    "\n",
    "    def loss_handler(self, recon, data, weight, latent, *args, **kwargs):\n",
    "        mu, log_var = self.vae_split(latent)\n",
    "        # here is the loss function computing\n",
    "        loss = torch.masked_select(\n",
    "            input = F.mse_loss(recon, data, reduction='none') * weight,\n",
    "            mask = weight.ge(0.0)).mean() + self.derivative_weight * torch.abs(\n",
    "            torch.diff(recon, dim=-1)\n",
    "            ).mean() + self.kld_weight * self.kld_loss(mu, log_var)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264423a5",
   "metadata": {},
   "source": [
    "## Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bbc5aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reparametrize_latent(vae, latent):\n",
    "    mu, log_var = vae.vae_split(latent)\n",
    "    var = np.exp(log_var)\n",
    "\n",
    "    mu, log_var = torch.tensor(mu), torch.tensor(log_var)\n",
    "    sample = vae.vae_reparametrize(mu, log_var).numpy()\n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f94fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dict_result(trainer, model, dataloader, ckpt_path):\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        trainer.test(model, dataloader, ckpt_path=ckpt_path)\n",
    "    model.test_result[\n",
    "        'labels'\n",
    "    ]=dataloader.dataset.label_enc.inverse_transform(\n",
    "    model.test_result[\n",
    "        'labels'\n",
    "        ].astype(int)\n",
    "    )\n",
    "\n",
    "    real = model.test_result['real'].squeeze()\n",
    "    recon = model.test_result['recon'].squeeze()\n",
    "    weight = model.test_result['weight'].squeeze()\n",
    "\n",
    "\n",
    "    weightedMSE = (real-recon)**2 * weight\n",
    "    pred_errors = (weightedMSE ** 0.5).tolist()\n",
    "\n",
    "    weightedMSE = np.ma.masked_array(data=weightedMSE,\n",
    "                                     mask=~(weight.astype(bool))\n",
    "    )\n",
    "    weightedMSE = weightedMSE.mean(axis=1, keepdims=True)\n",
    "\n",
    "    latent = model.test_result['latent'].copy()\n",
    "\n",
    "    if hasattr(model, 'vae_reparametrize') and callable(model.vae_reparametrize):\n",
    "        # for VAE, we must reparametrize latent first\n",
    "        latent = reparametrize_latent(model, latent)\n",
    "\n",
    "    latentdim = latent.shape[-1]\n",
    "\n",
    "    latent = pd.DataFrame(\n",
    "        data=np.concatenate((latent, weightedMSE), axis=1),\n",
    "        index=model.test_result['labels'],\n",
    "        columns=['feature_'+str(dim) for dim in range(latentdim)]+['wMSE'])\n",
    "\n",
    "    latent.insert(loc=latent_dim+1, column='pred_error', value=pred_errors)\n",
    "\n",
    "    return latent, real, recon, weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696ed457",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb227aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 3\n",
    "\n",
    "encoder, decoder = Encoder(latent_dim), Decoder(latent_dim)\n",
    "\n",
    "print(\">>> Encoder\")\n",
    "print(summary(encoder, (1, 64), device=\"cpu\"))\n",
    "\n",
    "print(\">>> Decoder\")\n",
    "print(summary(decoder, (1, latent_dim), device=\"cpu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86333e91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
