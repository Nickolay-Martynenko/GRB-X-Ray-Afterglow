{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1e983b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import sys\n",
    "\n",
    "from collections import defaultdict\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchmetrics\n",
    "from torchsummary import summary\n",
    "\n",
    "import lightning as L\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f02ec65",
   "metadata": {},
   "outputs": [],
   "source": [
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51a399b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilities.data_downloader import train_val_test_downloader\n",
    "from utilities.upsampling import upsampling\n",
    "from utilities.plots import plt, COLORMAP, visualize_latent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02593ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from warnings import simplefilter\n",
    "simplefilter(\"ignore\", category=RuntimeWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ace257d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def set_random_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "set_random_seed(42)\n",
    "L.seed_everything(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041bb83d",
   "metadata": {},
   "source": [
    "# Description\n",
    "\n",
    "bla bla"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "283a0e7d",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "bla bla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88282888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets downloaded\n",
      " - train  : 810 entries\n",
      " - val    : 174 entries\n",
      " - test   : 174 entries\n",
      " - labels : 1158 entries\n"
     ]
    }
   ],
   "source": [
    "train, val, test, labels = train_val_test_downloader('interp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8aad7011",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_upsampled = upsampling(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "20c1be3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LightCurveDataset(Dataset):\n",
    "    def __init__(self, dataframe:pd.DataFrame,\n",
    "                 data_col:str='lgRate',\n",
    "                 weight_col:str='weight'):\n",
    "        \n",
    "        data = np.array(dataframe.loc[:, data_col].tolist(),\n",
    "                        dtype=np.float32)\n",
    "        weight = np.array(dataframe.loc[:, weight_col].tolist(),\n",
    "                          dtype=np.float32)\n",
    "        \n",
    "        self.data = torch.from_numpy(\n",
    "            data).unsqueeze(dim=1)   # value\n",
    "        self.weight = torch.from_numpy(\n",
    "            weight).unsqueeze(dim=1) # weight\n",
    "\n",
    "        # using dataframe index = event names \n",
    "        # as labels\n",
    "        labels = dataframe.index\n",
    "        self.label_enc = LabelEncoder()\n",
    "        self.labels = torch.as_tensor(self.label_enc.fit_transform(labels))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx], self.weight[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ef36aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, val_dataset, test_dataset = (\n",
    "    LightCurveDataset(train_upsampled),\n",
    "    LightCurveDataset(val),\n",
    "    LightCurveDataset(test)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3687a665",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset,\n",
    "                          batch_size=256,\n",
    "                          shuffle=True,\n",
    "                          num_workers=2)\n",
    "val_loader = DataLoader(val_dataset,\n",
    "                        batch_size=256,\n",
    "                        shuffle=False,\n",
    "                        num_workers=2)\n",
    "test_loader = DataLoader(test_dataset,\n",
    "                         batch_size=256,\n",
    "                         shuffle=False,\n",
    "                         num_workers=2)\n",
    "\n",
    "# for predictions on non-augmented train:\n",
    "train_loader_ = DataLoader(LightCurveDataset(train),\n",
    "                           batch_size=256,\n",
    "                           shuffle=False,\n",
    "                           num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ced0b14",
   "metadata": {},
   "source": [
    "# Model\n",
    "bla bla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93d83db",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, latent_dim:int,\n",
    "                 architecture:tuple=(32, 4),\n",
    "                 tseries_length:int=64):\n",
    "        super().__init__()\n",
    "\n",
    "        self.hidden_dims = [\n",
    "            architecture[0]* 2**pow for pow in range(architecture[1])\n",
    "            ]                                       # num of filters in layers\n",
    "        self.tseries_length = tseries_length\n",
    "\n",
    "        modules = []\n",
    "        in_channels = 1                             # initial num of channels\n",
    "        for h_dim in self.hidden_dims:              # conv layers\n",
    "            modules.append(\n",
    "                nn.Sequential(\n",
    "                    nn.Conv1d(\n",
    "                        in_channels=in_channels,    # num of input channels\n",
    "                        out_channels=h_dim,         # num of output channels\n",
    "                        kernel_size=3,\n",
    "                        stride=2,                   # convolution kernel step\n",
    "                        padding=1,                  # save shape\n",
    "                    ),\n",
    "                    nn.BatchNorm1d(h_dim),\n",
    "                    nn.LeakyReLU(),\n",
    "                )\n",
    "            )\n",
    "            in_channels = h_dim                     # changing num of \n",
    "                                                    # input channels for \n",
    "                                                    # next iteration\n",
    "\n",
    "        modules.append(nn.Flatten())                # to vector\n",
    "        intermediate_dim = (\n",
    "            self.hidden_dims[-1] * \n",
    "            self.tseries_length // (2**len(self.hidden_dims))\n",
    "        )\n",
    "        modules.append(nn.Linear(in_features=intermediate_dim,\n",
    "                                 out_features=latent_dim))\n",
    "\n",
    "        self.encoder = nn.Sequential(*modules)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, latent_dim:int,\n",
    "                 architecture:tuple=(32, 4),\n",
    "                 tseries_length:int=64):\n",
    "        super().__init__()\n",
    "        self.hidden_dims = [\n",
    "            architecture[0]* 2**pow for pow in range(architecture[1]-1, 0, -1)\n",
    "            ]                                       # num of filters in layers\n",
    "        self.tseries_length = tseries_length\n",
    "\n",
    "        intermediate_dim = (\n",
    "            self.hidden_dims[0] * \n",
    "            self.tseries_length // (2**len(self.hidden_dims))\n",
    "        )\n",
    "        self.linear = nn.Linear(in_features=latent_dim,\n",
    "                                out_features=intermediate_dim)\n",
    "\n",
    "        modules = []\n",
    "        for i in range(len(self.hidden_dims) - 1):  # define upsample layers\n",
    "            modules.append(\n",
    "                nn.Sequential(\n",
    "                    nn.Upsample(scale_factor=2),\n",
    "                    nn.Conv1d(\n",
    "                        in_channels=self.hidden_dims[i],\n",
    "                        out_channels=self.hidden_dims[i + 1],\n",
    "                        kernel_size=3,\n",
    "                        padding=1,\n",
    "                    ),\n",
    "                    nn.BatchNorm1d(self.hidden_dims[i + 1]),\n",
    "                    nn.LeakyReLU(),\n",
    "                )\n",
    "            )\n",
    "\n",
    "        modules.append(\n",
    "            nn.Sequential(\n",
    "                nn.Upsample(scale_factor=2),\n",
    "                nn.Conv1d(in_channels=self.hidden_dims[-1],\n",
    "                          out_channels=1,\n",
    "                          kernel_size=3, padding=1)\n",
    "            )\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(*modules)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)        # from latents space to Linear\n",
    "        x = x.view(\n",
    "            -1, self.hidden_dims[0],\n",
    "            self.tseries_length // (2**len(self.hidden_dims))\n",
    "            )                     # reshape\n",
    "        x = self.decoder(x)       # reconstruction\n",
    "        return x\n",
    "\n",
    "class VAEncoder(Encoder):\n",
    "    def __init__(self, latent_dim):\n",
    "        if latent_dim % 2 != 0:   # check for the parity of the latent space\n",
    "            raise Exception('Latent size for VAEncoder must be even')\n",
    "\n",
    "        super().__init__(latent_dim)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
